{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"c4601d65-4658-4336-af80-c5012a70ffce","_cell_guid":"d37199b4-a713-4059-a005-a7c1ba52bec9","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-05-17T15:31:18.700233Z","iopub.execute_input":"2023-05-17T15:31:18.700622Z","iopub.status.idle":"2023-05-17T15:31:18.814592Z","shell.execute_reply.started":"2023-05-17T15:31:18.700585Z","shell.execute_reply":"2023-05-17T15:31:18.813463Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/aksharantar-sampled/aksharantar_sampled/brx/brx_test.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/brx/brx_valid.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/brx/brx_train.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/tam/tam_valid.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/tam/tam_train.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/tam/tam_test.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/mni/mni_valid.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/mni/mni_test.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/mni/mni_train.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/urd/urd_train.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/urd/urd_valid.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/urd/urd_test.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/kok/kok_valid.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/kok/kok_train.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/kok/kok_test.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/mai/mai_test.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/mai/mai_train.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/mai/mai_valid.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/guj/guj_test.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/guj/guj_train.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/guj/guj_valid.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/ben/ben_train.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/ben/ben_test.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/ben/ben_valid.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/tel/tel_test.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/tel/tel_valid.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/tel/tel_train.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/kas/kas_valid.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/kas/kas_train.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/kas/kas_test.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/kan/kan_valid.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/kan/kan_train.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/kan/kan_test.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/mal/mal_test.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/mal/mal_train.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/mal/mal_valid.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/pan/pan_valid.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/pan/pan_test.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/pan/pan_train.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/asm/asm_test.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/asm/asm_train.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/asm/asm_valid.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/sid/sid_train.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/sid/sid_test.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/sid/sid_valid.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/mar/mar_train.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/mar/mar_test.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/mar/mar_valid.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/san/san_train.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/san/san_valid.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/san/san_test.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/hin/hin_valid.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/hin/hin_test.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/hin/hin_train.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/ori/ori_test.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/ori/ori_train.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/ori/ori_valid.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms\nimport matplotlib.pyplot as plt\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch import optim\nimport gc\nimport random","metadata":{"_uuid":"0440d708-a23b-43b1-8c22-1498c6681ffa","_cell_guid":"5b63e89e-f815-4c0e-a9fd-f9df42201112","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-05-17T15:31:20.157323Z","iopub.execute_input":"2023-05-17T15:31:20.158336Z","iopub.status.idle":"2023-05-17T15:31:22.775601Z","shell.execute_reply.started":"2023-05-17T15:31:20.158286Z","shell.execute_reply":"2023-05-17T15:31:22.774467Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"if torch.cuda.is_available():\n    # If CUDA is available, use a CUDA device\n    device = torch.device(\"cuda\")\nelse:\n    # If CUDA is not available, use the CPU\n    device = torch.device(\"cpu\")","metadata":{"_uuid":"4ad55d90-05dc-4f85-89f3-3595b6bfafc6","_cell_guid":"d460c02e-61b4-4370-8716-44d06e373eae","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-05-17T15:31:22.778161Z","iopub.execute_input":"2023-05-17T15:31:22.778738Z","iopub.status.idle":"2023-05-17T15:31:22.873735Z","shell.execute_reply.started":"2023-05-17T15:31:22.778698Z","shell.execute_reply":"2023-05-17T15:31:22.872424Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"device","metadata":{"_uuid":"71053770-4945-4503-9cc9-bf4765a61c24","_cell_guid":"9f0d50cf-8946-492f-893f-c285328ce795","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-05-17T15:31:22.875526Z","iopub.execute_input":"2023-05-17T15:31:22.876410Z","iopub.status.idle":"2023-05-17T15:31:22.889666Z","shell.execute_reply.started":"2023-05-17T15:31:22.876358Z","shell.execute_reply":"2023-05-17T15:31:22.888461Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{"_uuid":"c18fbd13-2aed-44e1-9d6a-815ed62ec6a2","_cell_guid":"dd8bb88e-25ff-417d-92ba-323c4feeed3d","trusted":true}},{"cell_type":"code","source":"traindata = pd.read_csv('/kaggle/input/aksharantar-sampled/aksharantar_sampled/hin/hin_train.csv',names= ['English','Hindi'],header = None)","metadata":{"_uuid":"664dc735-d7ce-4931-9df5-e2dbfcf74c7e","_cell_guid":"885c926c-19d4-4bff-b18e-991c131bb768","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-05-17T15:31:22.893659Z","iopub.execute_input":"2023-05-17T15:31:22.894371Z","iopub.status.idle":"2023-05-17T15:31:23.016400Z","shell.execute_reply.started":"2023-05-17T15:31:22.894328Z","shell.execute_reply":"2023-05-17T15:31:23.015190Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"testdata = pd.read_csv('/kaggle/input/aksharantar-sampled/aksharantar_sampled/hin/hin_test.csv',names = ['English','Hindi'],header = None)","metadata":{"_uuid":"3258f852-ef18-44d4-8e6a-0f74c3d309a3","_cell_guid":"f2b9fb57-3943-484a-9f4c-10b91625dee9","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-05-17T15:31:23.018170Z","iopub.execute_input":"2023-05-17T15:31:23.018568Z","iopub.status.idle":"2023-05-17T15:31:23.034698Z","shell.execute_reply.started":"2023-05-17T15:31:23.018513Z","shell.execute_reply":"2023-05-17T15:31:23.033650Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"valdata = pd.read_csv('/kaggle/input/aksharantar-sampled/aksharantar_sampled/hin/hin_valid.csv',names = ['English','Hindi'],header = None)","metadata":{"_uuid":"53409359-42e1-4f1d-aeca-6de4d6356485","_cell_guid":"a32d73a8-3700-487d-a24f-e97949ecd3f6","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-05-17T15:31:23.038281Z","iopub.execute_input":"2023-05-17T15:31:23.038600Z","iopub.status.idle":"2023-05-17T15:31:23.056999Z","shell.execute_reply.started":"2023-05-17T15:31:23.038569Z","shell.execute_reply":"2023-05-17T15:31:23.055830Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"traindata","metadata":{"_uuid":"14b59fa8-110c-4a68-b720-9d73ded9916a","_cell_guid":"b048ee5d-9110-4f24-a3eb-d42b9f692128","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-05-17T15:31:23.060449Z","iopub.execute_input":"2023-05-17T15:31:23.060780Z","iopub.status.idle":"2023-05-17T15:31:23.081029Z","shell.execute_reply.started":"2023-05-17T15:31:23.060750Z","shell.execute_reply":"2023-05-17T15:31:23.080055Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"           English       Hindi\n0      shastragaar  शस्त्रागार\n1          bindhya    बिन्द्या\n2        kirankant    किरणकांत\n3      yagyopaveet   यज्ञोपवीत\n4          ratania     रटानिया\n...            ...         ...\n51195        toned        टोंड\n51196   mutanaazaa    मुतनाज़ा\n51197    asahmaton     असहमतों\n51198    sulgaayin    सुलगायीं\n51199  anchuthengu   अंचुतेंगु\n\n[51200 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>English</th>\n      <th>Hindi</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>shastragaar</td>\n      <td>शस्त्रागार</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>bindhya</td>\n      <td>बिन्द्या</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>kirankant</td>\n      <td>किरणकांत</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>yagyopaveet</td>\n      <td>यज्ञोपवीत</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ratania</td>\n      <td>रटानिया</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>51195</th>\n      <td>toned</td>\n      <td>टोंड</td>\n    </tr>\n    <tr>\n      <th>51196</th>\n      <td>mutanaazaa</td>\n      <td>मुतनाज़ा</td>\n    </tr>\n    <tr>\n      <th>51197</th>\n      <td>asahmaton</td>\n      <td>असहमतों</td>\n    </tr>\n    <tr>\n      <th>51198</th>\n      <td>sulgaayin</td>\n      <td>सुलगायीं</td>\n    </tr>\n    <tr>\n      <th>51199</th>\n      <td>anchuthengu</td>\n      <td>अंचुतेंगु</td>\n    </tr>\n  </tbody>\n</table>\n<p>51200 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def tokenize(word):\n    tokens = []\n    for x in word:\n        tokens.append(x)\n    return tokens","metadata":{"_uuid":"8c75f3d2-57d2-49d5-a54e-9c50fdcc4644","_cell_guid":"59dfdcf8-680e-45f1-8a4f-604d3711cef3","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-05-17T15:31:23.082842Z","iopub.execute_input":"2023-05-17T15:31:23.083813Z","iopub.status.idle":"2023-05-17T15:31:23.089353Z","shell.execute_reply.started":"2023-05-17T15:31:23.083772Z","shell.execute_reply":"2023-05-17T15:31:23.088065Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"tokenize(traindata.iloc[0]['Hindi'])","metadata":{"_uuid":"80652953-cd57-44f8-be2c-c263230059b1","_cell_guid":"91ca2b4b-969b-450d-8f47-536e37c0402c","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-05-17T15:31:23.090935Z","iopub.execute_input":"2023-05-17T15:31:23.091888Z","iopub.status.idle":"2023-05-17T15:31:23.103591Z","shell.execute_reply.started":"2023-05-17T15:31:23.091799Z","shell.execute_reply":"2023-05-17T15:31:23.102451Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"['श', 'स', '्', 'त', '्', 'र', 'ा', 'ग', 'ा', 'र']"},"metadata":{}}]},{"cell_type":"code","source":"max_eng_len = 0\nmax_hin_len = 0","metadata":{"_uuid":"e1d4d6a9-6dcf-47d0-a7e4-ec0cdb548715","_cell_guid":"d26cd97b-7db1-4f2b-b108-fcfafeab26e9","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-05-17T15:31:23.107280Z","iopub.execute_input":"2023-05-17T15:31:23.107784Z","iopub.status.idle":"2023-05-17T15:31:23.112862Z","shell.execute_reply.started":"2023-05-17T15:31:23.107746Z","shell.execute_reply":"2023-05-17T15:31:23.111662Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"test_max_eng_len = 0\ntest_max_hin_len = 0","metadata":{"_uuid":"fca4d5a5-5944-42dc-b6ef-613cbb1c5843","_cell_guid":"cd807384-6d73-4abb-8bf2-db6ee5065e8d","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-05-17T15:31:23.324132Z","iopub.execute_input":"2023-05-17T15:31:23.325026Z","iopub.status.idle":"2023-05-17T15:31:23.330293Z","shell.execute_reply.started":"2023-05-17T15:31:23.324932Z","shell.execute_reply":"2023-05-17T15:31:23.329083Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"for x in range(len(testdata)):\n    temp = 0\n    for y in testdata.iloc[x]['English']:\n        temp+=1\n    test_max_eng_len = max(test_max_eng_len,temp)\nprint(test_max_eng_len)","metadata":{"_uuid":"d5b5ba63-74b7-451a-bb2e-f3c61d8cba93","_cell_guid":"82623430-8dc5-4e5b-b26c-72641b4ec33f","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-05-17T15:31:23.500373Z","iopub.execute_input":"2023-05-17T15:31:23.500757Z","iopub.status.idle":"2023-05-17T15:31:23.805142Z","shell.execute_reply.started":"2023-05-17T15:31:23.500722Z","shell.execute_reply":"2023-05-17T15:31:23.803918Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"26\n","output_type":"stream"}]},{"cell_type":"code","source":"for x in range(len(testdata)):\n    temp = 0\n    for y in testdata.iloc[x]['Hindi']:\n        temp +=1\n    test_max_hin_len = max(test_max_hin_len,temp)\nprint(test_max_hin_len)","metadata":{"_uuid":"6e59ee86-b167-46ad-9dda-8ec367de6ad6","_cell_guid":"a2359141-3503-4e6c-b41f-47a62b498c8a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-05-17T15:31:23.915360Z","iopub.execute_input":"2023-05-17T15:31:23.915785Z","iopub.status.idle":"2023-05-17T15:31:24.222683Z","shell.execute_reply.started":"2023-05-17T15:31:23.915750Z","shell.execute_reply":"2023-05-17T15:31:24.221397Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"20\n","output_type":"stream"}]},{"cell_type":"code","source":"val_max_eng_len = 0\nval_max_hin_len = 0","metadata":{"_uuid":"88973c4d-68ce-44f3-8d90-253469182f45","_cell_guid":"d915e294-3008-427a-bff3-b3e117157921","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-05-17T15:31:24.224756Z","iopub.execute_input":"2023-05-17T15:31:24.225712Z","iopub.status.idle":"2023-05-17T15:31:24.231430Z","shell.execute_reply.started":"2023-05-17T15:31:24.225677Z","shell.execute_reply":"2023-05-17T15:31:24.230007Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"for x in range(len(valdata)):\n    temp = 0\n    for y in valdata.iloc[x]['English']:\n        temp+=1\n    val_max_eng_len = max(val_max_eng_len,temp)\nprint(val_max_eng_len)","metadata":{"_uuid":"d3b544d8-8ece-4c20-9228-0c0dbc58481a","_cell_guid":"b214859c-1121-444d-93b8-7061641321de","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-05-17T15:31:24.233249Z","iopub.execute_input":"2023-05-17T15:31:24.234002Z","iopub.status.idle":"2023-05-17T15:31:24.551177Z","shell.execute_reply.started":"2023-05-17T15:31:24.233939Z","shell.execute_reply":"2023-05-17T15:31:24.549901Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"22\n","output_type":"stream"}]},{"cell_type":"code","source":"for x in range(len(valdata)):\n    temp = 0\n    for y in valdata.iloc[x]['Hindi']:\n        temp+=1\n    val_max_hin_len = max(val_max_hin_len,temp)\nprint(val_max_hin_len)","metadata":{"_uuid":"230cc813-2b43-4a37-bd63-7d6d97bd3abc","_cell_guid":"59a77ebc-b2aa-498f-8ca6-74f1cc4e650e","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-05-17T15:31:24.553769Z","iopub.execute_input":"2023-05-17T15:31:24.554496Z","iopub.status.idle":"2023-05-17T15:31:24.853553Z","shell.execute_reply.started":"2023-05-17T15:31:24.554451Z","shell.execute_reply":"2023-05-17T15:31:24.852305Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"20\n","output_type":"stream"}]},{"cell_type":"code","source":"English_vocab = []\nfor x in range(len(traindata)):\n    temp = 0\n    for y in traindata.iloc[x]['English']:\n        temp += 1\n        if y not in English_vocab:\n            English_vocab.append(y)\n    if(temp>max_eng_len):\n        max_eng_len = max(max_eng_len,temp)\nprint(sorted(English_vocab))\nprint(max_eng_len)","metadata":{"_uuid":"90fc354e-ed6b-47cc-af5a-060f6dcb08d8","_cell_guid":"17c1657d-3f80-4ede-b08b-68858238e63e","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-05-17T15:31:24.855552Z","iopub.execute_input":"2023-05-17T15:31:24.856601Z","iopub.status.idle":"2023-05-17T15:31:28.737302Z","shell.execute_reply.started":"2023-05-17T15:31:24.856564Z","shell.execute_reply":"2023-05-17T15:31:28.735941Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n24\n","output_type":"stream"}]},{"cell_type":"code","source":"Hindi_vocab = []\nfor x in range(len(traindata)):\n    temp = 0\n    for y in traindata.iloc[x]['Hindi']:\n        temp += 1\n        if y not in Hindi_vocab:\n            Hindi_vocab.append(y)\n    max_hin_len = max(temp,max_hin_len)\nfor x in range(len(testdata)):\n    for y in testdata.iloc[x]['Hindi']:\n        if y not in Hindi_vocab:\n            print(y)\n            Hindi_vocab.append(y)","metadata":{"_uuid":"22978cf7-6b90-49d3-960d-39f6250ec30e","_cell_guid":"fe0d065e-65db-497f-b2f7-454eed2fc32e","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-05-17T15:31:28.739014Z","iopub.execute_input":"2023-05-17T15:31:28.739506Z","iopub.status.idle":"2023-05-17T15:31:32.906846Z","shell.execute_reply.started":"2023-05-17T15:31:28.739463Z","shell.execute_reply":"2023-05-17T15:31:32.905718Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"ॊ\n","output_type":"stream"}]},{"cell_type":"code","source":"print(max_hin_len)","metadata":{"_uuid":"47c672a4-7b7b-4965-be21-8b1c1c8024a5","_cell_guid":"78fc856b-5bd7-4c9c-b07e-7f5d607f8cd5","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-05-17T15:31:32.910065Z","iopub.execute_input":"2023-05-17T15:31:32.910935Z","iopub.status.idle":"2023-05-17T15:31:32.920060Z","shell.execute_reply.started":"2023-05-17T15:31:32.910876Z","shell.execute_reply":"2023-05-17T15:31:32.917238Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"20\n","output_type":"stream"}]},{"cell_type":"code","source":"English_vocab = sorted(English_vocab)\nHindi_vocab = sorted(Hindi_vocab)","metadata":{"_uuid":"c5515812-abf9-44bd-8be1-109bd78069f5","_cell_guid":"12622194-f76a-46ab-96f8-f28ac066233b","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-05-17T15:31:32.923196Z","iopub.execute_input":"2023-05-17T15:31:32.924355Z","iopub.status.idle":"2023-05-17T15:31:32.930623Z","shell.execute_reply.started":"2023-05-17T15:31:32.924304Z","shell.execute_reply":"2023-05-17T15:31:32.929159Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"Eng_dict = {}\nreverse_Eng = {}\n\nfor x in range(len(English_vocab)):\n    Eng_dict[English_vocab[x]] = x+3\n    reverse_Eng[x+3] = English_vocab[x]\nEng_dict['<sow>'] = 0\nEng_dict['<eow>'] = 1\nEng_dict['<pad>'] = 2\nreverse_Eng[0] = '<sow>'\nreverse_Eng[1] = '<eow>'\nreverse_Eng[2] = '<pad>'\n\nprint(Eng_dict)\nprint(reverse_Eng)","metadata":{"_uuid":"49669708-6d8d-474b-a47b-2110e18f2b94","_cell_guid":"c48841c4-f778-4d98-9f64-a426e9ff1420","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-05-17T15:31:32.933326Z","iopub.execute_input":"2023-05-17T15:31:32.934392Z","iopub.status.idle":"2023-05-17T15:31:32.948043Z","shell.execute_reply.started":"2023-05-17T15:31:32.934212Z","shell.execute_reply":"2023-05-17T15:31:32.946398Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"{'a': 3, 'b': 4, 'c': 5, 'd': 6, 'e': 7, 'f': 8, 'g': 9, 'h': 10, 'i': 11, 'j': 12, 'k': 13, 'l': 14, 'm': 15, 'n': 16, 'o': 17, 'p': 18, 'q': 19, 'r': 20, 's': 21, 't': 22, 'u': 23, 'v': 24, 'w': 25, 'x': 26, 'y': 27, 'z': 28, '<sow>': 0, '<eow>': 1, '<pad>': 2}\n{3: 'a', 4: 'b', 5: 'c', 6: 'd', 7: 'e', 8: 'f', 9: 'g', 10: 'h', 11: 'i', 12: 'j', 13: 'k', 14: 'l', 15: 'm', 16: 'n', 17: 'o', 18: 'p', 19: 'q', 20: 'r', 21: 's', 22: 't', 23: 'u', 24: 'v', 25: 'w', 26: 'x', 27: 'y', 28: 'z', 0: '<sow>', 1: '<eow>', 2: '<pad>'}\n","output_type":"stream"}]},{"cell_type":"code","source":"Hin_dict = {}\nreverse_Hin = {}\nfor x in range(len(Hindi_vocab)):\n    Hin_dict[Hindi_vocab[x]] = x+3\n    reverse_Hin[x+3] = Hindi_vocab[x]\nHin_dict['<sow>'] = 0\nHin_dict['<eow>'] = 1\nHin_dict['<pad>'] = 2\nreverse_Hin[0] = '<sow>'\nreverse_Hin[1] = '<eow>'\nreverse_Hin[2] = '<pad>'\nprint(Hin_dict)\nprint(reverse_Hin)","metadata":{"_uuid":"2c147579-c2dd-4bcf-a732-c5b2f7aff5c9","_cell_guid":"e24b164d-d28a-4765-8a5a-0994e49d7863","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-05-17T15:31:32.950359Z","iopub.execute_input":"2023-05-17T15:31:32.951383Z","iopub.status.idle":"2023-05-17T15:31:32.961916Z","shell.execute_reply.started":"2023-05-17T15:31:32.951341Z","shell.execute_reply":"2023-05-17T15:31:32.960519Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"{'ँ': 3, 'ं': 4, 'ः': 5, 'अ': 6, 'आ': 7, 'इ': 8, 'ई': 9, 'उ': 10, 'ऊ': 11, 'ऋ': 12, 'ए': 13, 'ऐ': 14, 'ऑ': 15, 'ओ': 16, 'औ': 17, 'क': 18, 'ख': 19, 'ग': 20, 'घ': 21, 'ङ': 22, 'च': 23, 'छ': 24, 'ज': 25, 'झ': 26, 'ञ': 27, 'ट': 28, 'ठ': 29, 'ड': 30, 'ढ': 31, 'ण': 32, 'त': 33, 'थ': 34, 'द': 35, 'ध': 36, 'न': 37, 'प': 38, 'फ': 39, 'ब': 40, 'भ': 41, 'म': 42, 'य': 43, 'र': 44, 'ल': 45, 'ळ': 46, 'व': 47, 'श': 48, 'ष': 49, 'स': 50, 'ह': 51, '़': 52, 'ऽ': 53, 'ा': 54, 'ि': 55, 'ी': 56, 'ु': 57, 'ू': 58, 'ृ': 59, 'ॅ': 60, 'े': 61, 'ै': 62, 'ॉ': 63, 'ॊ': 64, 'ो': 65, 'ौ': 66, '्': 67, '<sow>': 0, '<eow>': 1, '<pad>': 2}\n{3: 'ँ', 4: 'ं', 5: 'ः', 6: 'अ', 7: 'आ', 8: 'इ', 9: 'ई', 10: 'उ', 11: 'ऊ', 12: 'ऋ', 13: 'ए', 14: 'ऐ', 15: 'ऑ', 16: 'ओ', 17: 'औ', 18: 'क', 19: 'ख', 20: 'ग', 21: 'घ', 22: 'ङ', 23: 'च', 24: 'छ', 25: 'ज', 26: 'झ', 27: 'ञ', 28: 'ट', 29: 'ठ', 30: 'ड', 31: 'ढ', 32: 'ण', 33: 'त', 34: 'थ', 35: 'द', 36: 'ध', 37: 'न', 38: 'प', 39: 'फ', 40: 'ब', 41: 'भ', 42: 'म', 43: 'य', 44: 'र', 45: 'ल', 46: 'ळ', 47: 'व', 48: 'श', 49: 'ष', 50: 'स', 51: 'ह', 52: '़', 53: 'ऽ', 54: 'ा', 55: 'ि', 56: 'ी', 57: 'ु', 58: 'ू', 59: 'ृ', 60: 'ॅ', 61: 'े', 62: 'ै', 63: 'ॉ', 64: 'ॊ', 65: 'ो', 66: 'ौ', 67: '्', 0: '<sow>', 1: '<eow>', 2: '<pad>'}\n","output_type":"stream"}]},{"cell_type":"code","source":"def Eng_tokenize(word):\n    tokens = []\n    for x in word:\n        tokens.append(Eng_dict[x])\n    for x in range(len(tokens),max_eng_len):\n        tokens.append(Eng_dict['<pad>'])\n    return tokens","metadata":{"_uuid":"e90c5abd-5f9a-4ca3-b271-c4fd1b570daa","_cell_guid":"f068a919-7a52-4ecb-b6eb-a8fbe9909183","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-05-17T15:31:32.964651Z","iopub.execute_input":"2023-05-17T15:31:32.965585Z","iopub.status.idle":"2023-05-17T15:31:32.973043Z","shell.execute_reply.started":"2023-05-17T15:31:32.965544Z","shell.execute_reply":"2023-05-17T15:31:32.971966Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"Eng_tokenize(traindata.iloc[0]['English'])","metadata":{"execution":{"iopub.status.busy":"2023-05-17T15:31:32.978402Z","iopub.execute_input":"2023-05-17T15:31:32.978890Z","iopub.status.idle":"2023-05-17T15:31:32.987227Z","shell.execute_reply.started":"2023-05-17T15:31:32.978860Z","shell.execute_reply":"2023-05-17T15:31:32.985785Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"[21, 10, 3, 21, 22, 20, 3, 9, 3, 3, 20, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"},"metadata":{}}]},{"cell_type":"code","source":"def Hin_tokenize(word):\n    tokens = []\n    for x in word:\n        tokens.append(Hin_dict[x])\n    tokens.append(Hin_dict['<eow>'])\n    for x in range(len(tokens),max_hin_len+1):\n        tokens.append(Hin_dict['<pad>'])\n    return tokens","metadata":{"_uuid":"ec37e1fe-4d67-4d68-b057-9aa3603b38e9","_cell_guid":"756b601d-530c-43d2-aa7b-83e7247dbe9a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-05-17T15:31:32.989480Z","iopub.execute_input":"2023-05-17T15:31:32.989963Z","iopub.status.idle":"2023-05-17T15:31:32.997693Z","shell.execute_reply.started":"2023-05-17T15:31:32.989902Z","shell.execute_reply":"2023-05-17T15:31:32.996359Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"eng_word = []\nhin_word = []\nfor x in range(len(traindata)):\n    eng_word.append(Eng_tokenize(traindata.iloc[x]['English']))\n    hin_word.append(Hin_tokenize(traindata.iloc[x]['Hindi']))","metadata":{"_uuid":"fa8271a6-e6d9-4aaa-b8b7-2ee24be20784","_cell_guid":"33831232-5aa7-4e42-bccf-d830024baf96","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-05-17T15:31:32.999128Z","iopub.execute_input":"2023-05-17T15:31:32.999910Z","iopub.status.idle":"2023-05-17T15:31:41.362105Z","shell.execute_reply.started":"2023-05-17T15:31:32.999871Z","shell.execute_reply":"2023-05-17T15:31:41.360929Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"eng_word = torch.tensor(eng_word)\nhin_word = torch.tensor(hin_word)","metadata":{"_uuid":"4dedad10-9345-4ea9-b4f2-1f1b6dda3445","_cell_guid":"54539805-0adc-431d-980b-963054328c20","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-05-17T15:31:41.363503Z","iopub.execute_input":"2023-05-17T15:31:41.363863Z","iopub.status.idle":"2023-05-17T15:31:41.699059Z","shell.execute_reply.started":"2023-05-17T15:31:41.363824Z","shell.execute_reply":"2023-05-17T15:31:41.697889Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"max_hin_len","metadata":{"_uuid":"4b4de747-4e77-4cae-8994-370aa21c0bf4","_cell_guid":"4810a2c4-8f66-46b9-a64d-474ccc1f777d","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-05-17T15:31:41.700567Z","iopub.execute_input":"2023-05-17T15:31:41.700974Z","iopub.status.idle":"2023-05-17T15:31:41.711153Z","shell.execute_reply.started":"2023-05-17T15:31:41.700918Z","shell.execute_reply":"2023-05-17T15:31:41.709978Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"20"},"metadata":{}}]},{"cell_type":"code","source":"max_hin_len += 1\ntest_max_hin_len += 1\nval_max_hin_len += 1","metadata":{"_uuid":"83d3f8a3-1e17-48cd-9ae9-31eea5e2da68","_cell_guid":"e6ace465-847e-439b-8dc4-3ef3189b429b","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-05-17T15:31:41.713074Z","iopub.execute_input":"2023-05-17T15:31:41.713793Z","iopub.status.idle":"2023-05-17T15:31:41.718841Z","shell.execute_reply.started":"2023-05-17T15:31:41.713755Z","shell.execute_reply":"2023-05-17T15:31:41.717382Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"max_hin_len","metadata":{"_uuid":"845aac0d-e1b7-4da1-b9af-6a68127826d8","_cell_guid":"d5e35d8b-ebdb-4566-b53b-b716f13a654b","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-05-17T15:31:41.720804Z","iopub.execute_input":"2023-05-17T15:31:41.721574Z","iopub.status.idle":"2023-05-17T15:31:41.730510Z","shell.execute_reply.started":"2023-05-17T15:31:41.721535Z","shell.execute_reply":"2023-05-17T15:31:41.729408Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"21"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"_uuid":"34f20433-4b05-437f-ac36-95e8136afd53","_cell_guid":"8c089c69-7548-4085-b35b-a94d45ddb94c","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test_Eng_tokenize(word):\n    tokens = []\n    for x in word:\n        tokens.append(Eng_dict[x])\n    for x in range(len(tokens),test_max_eng_len):\n        tokens.append(Eng_dict['<pad>'])\n    return tokens\ndef test_Hin_tokenize(word):\n    tokens = []\n    for x in word:\n        tokens.append(Hin_dict[x])\n    tokens.append(Hin_dict['<eow>'])\n    for x in range(len(tokens),test_max_hin_len):\n        tokens.append(Hin_dict['<pad>'])\n    return tokens\ndef val_Eng_tokenize(word):\n    tokens = []\n    for x in word:\n        tokens.append(Eng_dict[x])\n    for x in range(len(tokens),val_max_eng_len):\n        tokens.append(Eng_dict['<pad>'])\n    return tokens\ndef val_Hin_tokenize(word):\n    tokens = []\n    for x in word:\n        tokens.append(Hin_dict[x])\n    tokens.append(Hin_dict['<eow>'])\n    for x in range(len(tokens),val_max_hin_len):\n        tokens.append(Hin_dict['<pad>'])\n    return tokens\nval_eng_word = []\nval_hin_word = []\nfor x in range(len(valdata)):\n    val_eng_word.append(val_Eng_tokenize(valdata.iloc[x]['English']))\n    val_hin_word.append(val_Hin_tokenize(valdata.iloc[x]['Hindi']))\nval_eng_word = torch.tensor(val_eng_word)\nval_hin_word = torch.tensor(val_hin_word)\ntest_eng_word = []\ntest_hin_word = []\nfor x in range(len(testdata)):\n    test_eng_word.append(test_Eng_tokenize(testdata.iloc[x]['English']))\n    test_hin_word.append(test_Hin_tokenize(testdata.iloc[x]['Hindi']))\ntest_eng_word = torch.tensor(test_eng_word)\ntest_hin_word = torch.tensor(test_hin_word)","metadata":{"_uuid":"c615520b-2317-4459-b4f1-fef0ee93a07f","_cell_guid":"5754d5bf-a95a-45db-86e3-3c14cdceaa1a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-05-17T15:31:41.732347Z","iopub.execute_input":"2023-05-17T15:31:41.732768Z","iopub.status.idle":"2023-05-17T15:31:43.019495Z","shell.execute_reply.started":"2023-05-17T15:31:41.732670Z","shell.execute_reply":"2023-05-17T15:31:43.018378Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"# Encoder, Decoder and Attention","metadata":{"_uuid":"21b8a006-e556-4edb-82f2-df98f27f1b78","_cell_guid":"5f3e63d0-8ba4-44d6-b318-40c04b9b5851","trusted":true}},{"cell_type":"code","source":"class Encoder(nn.Module):\n    def __init__(self,char_embed_size,hidden_size,no_of_layers,dropout,rnn):\n        super(Encoder,self).__init__()\n        self.layer = no_of_layers\n        self.rnn = rnn\n        self.embedding = nn.Embedding(len(Eng_dict),char_embed_size).to(device)\n        self.embedding.weight.requires_grad = True\n        self.drop = nn.Dropout(dropout)\n        self.LSTM = nn.LSTM(char_embed_size,hidden_size,self.layer,batch_first = True,bidirectional = True).to(device)\n        self.RNN = nn.RNN(char_embed_size,hidden_size,self.layer,batch_first = True,bidirectional = True).to(device)\n        self.GRU = nn.GRU(char_embed_size,hidden_size,self.layer,batch_first = True,bidirectional = True).to(device)\n    def forward(self,input,hidden,cell):\n        embedded = self.embedding(input)\n        embedded1 = self.drop(embedded)\n        cell1 = cell\n        if(self.rnn == 'RNN'):\n            output,hidden1 = self.RNN(embedded1,hidden)\n        elif(self.rnn == 'LSTM'):\n            output,(hidden1,cell1) = self.LSTM(embedded1,(hidden,cell))\n        elif(self.rnn == 'GRU'):\n            output,hidden1 = self.GRU(embedded1,hidden)\n        return output,(hidden1,cell1)","metadata":{"_uuid":"4c3a2713-30c3-41f8-b319-19f22be41932","_cell_guid":"0bd66480-6ea4-45ba-9677-4e5b9454b97d","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-05-17T15:31:43.020989Z","iopub.execute_input":"2023-05-17T15:31:43.021361Z","iopub.status.idle":"2023-05-17T15:31:43.034851Z","shell.execute_reply.started":"2023-05-17T15:31:43.021321Z","shell.execute_reply":"2023-05-17T15:31:43.032175Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"class Decoder(nn.Module):\n    def __init__(self,char_embed_size,hidden_size,no_of_layers,dropout,batchsize,rnn):\n        super(Decoder,self).__init__()\n        self.layer = no_of_layers\n        self.batchsize = batchsize\n        self.hidden_size = hidden_size\n        self.rnn = rnn\n        self.embedding = nn.Embedding(len(Hin_dict),char_embed_size).to(device)\n        self.drop = nn.Dropout(dropout)\n        self.embedding.weight.requires_grad = True\n        self.LSTM = nn.LSTM(char_embed_size + hidden_size*2,hidden_size,self.layer,batch_first = True).to(device)\n        self.RNN = nn.RNN(char_embed_size + hidden_size*2,hidden_size,self.layer,batch_first = True).to(device)\n        self.GRU = nn.GRU(char_embed_size + hidden_size*2,hidden_size,self.layer,batch_first = True).to(device)\n        #2*hidden_size\n        self.linear = nn.Linear(hidden_size,len(Hin_dict),bias=True).to(device)\n        # dim = 2 \n        self.softmax = nn.Softmax(dim = 2).to(device)\n    def forward(self,input,hidden,cell,OGhidden):\n        embedded = self.embedding(input)\n        embedded1 = torch.cat((embedded,OGhidden[0].resize(self.batchsize,1,self.hidden_size),OGhidden[1].resize(self.batchsize,1,self.hidden_size)),dim = 2)\n        embedded2 = self.drop(embedded1)\n        cell1 = cell\n        if(self.rnn == 'LSTM'):\n            output,(hidden1,cell1) = self.LSTM(embedded2,(hidden,cell))\n        elif(self.rnn == 'RNN'):\n            output,hidden1 = self.RNN(embedded2,hidden)\n        elif(self.rnn == 'GRU'):\n            output,hidden1 = self.GRU(embedded2,hidden)\n        output1 = self.linear(output)\n        return output1,(hidden1,cell1)\n        output2 = self.softmax(output1)\n        return output2,hidden11\n        \n    #changed GRU char_embed_size\n    #changed forward embedded","metadata":{"_uuid":"b0dd3f8b-496b-46cb-8cd8-d87f0dbbcd1a","_cell_guid":"403b7350-7db5-4632-9bcc-b621457d4956","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-05-17T15:31:43.037024Z","iopub.execute_input":"2023-05-17T15:31:43.037933Z","iopub.status.idle":"2023-05-17T15:31:43.055501Z","shell.execute_reply.started":"2023-05-17T15:31:43.037888Z","shell.execute_reply":"2023-05-17T15:31:43.054176Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"class Attention(nn.Module):\n    def __init__(self,char_embed_size,hidden_size,no_of_layers,dropout,batchsize,rnn):\n        super(Attention,self).__init__()\n        self.layer = no_of_layers\n        self.batchsize = batchsize\n        self.hidden_size = hidden_size\n        self.rnn = rnn\n        self.embedding = nn.Embedding(len(Hin_dict),char_embed_size).to(device)\n        self.drop = nn.Dropout(dropout)\n        self.embedding.weight.requires_grad = True\n        self.U = nn.Linear(hidden_size,hidden_size,bias = False).to(device)\n        self.W = nn.Linear(hidden_size,hidden_size,bias = False).to(device)\n        self.V = nn.Linear(hidden_size,1,bias = False).to(device)\n        self.LSTM = nn.LSTM(char_embed_size + hidden_size,hidden_size,self.layer,batch_first = True).to(device)\n        self.RNN = nn.RNN(char_embed_size + hidden_size,hidden_size,self.layer,batch_first = True).to(device)\n        self.GRU = nn.GRU(char_embed_size + hidden_size,hidden_size,self.layer,batch_first = True).to(device) \n        self.linear = nn.Linear(hidden_size,len(Hin_dict),bias=True).to(device)\n        self.softmax = nn.Softmax(dim = 2).to(device)\n    def forward(self,input,hidden,cell,encoder_outputs):\n        embedded = self.embedding(input)\n        temp1 = self.U(encoder_outputs)\n        temp2 = self.W(hidden[-1])\n        add = temp1 + temp2.resize(self.batchsize,1,self.hidden_size)\n        tanh = F.tanh(add)\n        ejt = self.V(tanh)\n        ajt = nn.Softmax(dim = 1)(ejt)\n        ct = torch.zeros(self.batchsize,1,self.hidden_size).to(device)\n        ct = torch.bmm(ajt.transpose(1,2),encoder_outputs)\n        final_input = torch.cat((embedded,ct),dim = 2)\n        cell1 = cell\n        if(self.rnn == 'LSTM'):\n            output,(hidden1,cell1) = self.LSTM(final_input,(hidden,cell))\n        elif(self.rnn == 'RNN'):\n            output,hidden1 = self.RNN(final_input,hidden)\n        elif(self.rnn == 'GRU'):\n            output,hidden1 = self.GRU(final_input,hidden)\n        output1 = self.linear(output)\n        return output1,(hidden1,cell1)","metadata":{"_uuid":"887148a1-a58c-40ee-b566-419a88752f47","_cell_guid":"d4d898c9-ab14-4349-8c0d-898395cee481","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-05-17T15:31:43.061314Z","iopub.execute_input":"2023-05-17T15:31:43.061635Z","iopub.status.idle":"2023-05-17T15:31:43.081280Z","shell.execute_reply.started":"2023-05-17T15:31:43.061605Z","shell.execute_reply":"2023-05-17T15:31:43.080141Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"# Attentiontrain, train, Evaluate, valevaluate","metadata":{"_uuid":"dafbed96-4307-4c20-9d1b-5fe57fb9b919","_cell_guid":"4ef0d083-6526-4369-87f7-3f7a79310e42","trusted":true}},{"cell_type":"code","source":"def Evaluate(attention,test_eng_word,test_hin_word,encoder,decoder,batchsize,hidden_size,char_embed_size,no_of_layers):\n    with torch.no_grad():\n        total_loss = 0\n        total_acc = 0\n        en_hidden = torch.zeros(2*no_of_layers,batchsize,hidden_size).to(device)\n        en_cell = torch.zeros(2*no_of_layers,batchsize,hidden_size).to(device)\n        for x in range(0,len(testdata),batchsize):\n            loss = 0\n            input_tensor = test_eng_word[x:x+batchsize].to(device)\n#             en_hidden = torch.zeros(2*no_of_layers,batchsize,hidden_size).to(device)\n            if(input_tensor.size()[0] < batchsize):\n                break\n            output,(hidden,cell) = encoder.forward(input_tensor,en_hidden,en_cell)\n            del(input_tensor)\n            output = torch.split(output,[hidden_size,hidden_size],dim = 2)\n            output = torch.add(output[0],output[1])/2\n            input2 = []\n            for y in range(batchsize):\n                input2.append([0])\n            input2 = torch.tensor(input2).to(device)\n            hidden = hidden.resize(2,no_of_layers,batchsize,hidden_size)\n            hidden1 = torch.add(hidden[0],hidden[1])/2\n#             hidden1 = hidden[0]\n            cell = cell.resize(2,no_of_layers,batchsize,hidden_size)\n            cell1 = torch.add(cell[0],cell[1])/2\n#             cell1 = cell[0]\n            OGhidden = hidden1\n            predicted = []\n            predictions = []\n            if(attention == True):\n                temp = output\n            else:\n                temp = OGhidden\n            for i in range(test_max_hin_len):\n                output1,(hidden1,cell1) = decoder.forward(input2,hidden1,cell1,temp)\n                predicted.append(output1)\n                output2 = decoder.softmax(output1)\n                output3 = torch.argmax(output2,dim = 2)\n                predictions.append(output3)\n                input2 = output3\n            predicted = torch.cat(tuple(x for x in predicted),dim =1).to(device).resize(test_max_hin_len*batchsize,len(Hin_dict))\n            predictions = torch.cat(tuple(x for x in predictions),dim =1).to(device)\n            total_acc += accuracy(test_hin_word[x:x+batchsize].to(device),predictions,x)\n            loss  = nn.CrossEntropyLoss(reduction = 'sum')(predicted,test_hin_word[x:x+batchsize].reshape(-1).to(device))\n            with torch.no_grad():\n                total_loss += loss.item()\n#         print('test_loss')\n        test_loss = total_loss/(len(testdata)*test_max_hin_len)\n#         print(test_loss)\n#         print('test_accuracy')\n        test_accuracy = (total_acc/len(testdata))*100\n#         print(test_accuracy)\n        del(predictions)\n        del(predicted)\n        del(input2)\n        del(output1)\n        del(output2)\n        del(output3)\n        del(hidden1)\n        del(cell1)\n        del(OGhidden)\n        del(output)\n        del(cell)\n        return test_loss,test_accuracy","metadata":{"_uuid":"bb76d714-7ce0-4f72-af49-b0ec91b833aa","_cell_guid":"503da80f-e824-43be-9c4e-1529fbd79d72","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-05-17T15:31:43.083647Z","iopub.execute_input":"2023-05-17T15:31:43.084147Z","iopub.status.idle":"2023-05-17T15:31:43.108695Z","shell.execute_reply.started":"2023-05-17T15:31:43.084104Z","shell.execute_reply":"2023-05-17T15:31:43.107360Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"import math\n\ndef tempvalevaluate(attention, eng_word, hin_word, encoder, decoder, batch_size, hidden_size, char_embed_size, no_of_layers, beam_width):\n    with torch.no_grad():\n        total_loss = 0\n        total_acc = 0\n        for x in range(0, len(eng_word), batch_size):\n            input_tensor = eng_word[x:x+batch_size].to(device)\n            if input_tensor.size()[0] < batch_size:\n                break\n            en_hidden = torch.zeros(2*no_of_layers, batch_size, hidden_size).to(device)\n            en_cell = torch.zeros(2*no_of_layers, batch_size, hidden_size).to(device)\n            output, (hidden, cell) = encoder.forward(input_tensor, en_hidden, en_cell)\n            del(input_tensor)\n            del(en_hidden)\n            del(en_cell)\n            output = torch.split(output, [hidden_size, hidden_size], dim=2)\n            output = torch.add(output[0], output[1])/2\n            hidden = hidden.resize(2, no_of_layers, batch_size, hidden_size)\n            hidden1 = torch.add(hidden[0], hidden[1])/2\n            cell = cell.resize(2, no_of_layers, batch_size, hidden_size)\n            cell1 = torch.add(cell[0], cell[1])/2\n            OGhidden = hidden1\n            if attention:\n                temp = output\n            else:\n                temp = OGhidden\n            # initialize beam\n            beam = [(0, [0]*batchsize, hidden1, cell1)]  # Start with <SOS> token\n            for i in range(val_max_hin_len):\n                new_beam = []\n                for score, sequence, hidden1, cell1 in beam:\n                    if sequence[-1] == 1:  # <EOS> token\n                        new_beam.append((score, sequence, hidden1, cell1))\n                        continue\n                    input2 = torch.tensor([sequence[-1]]).unsqueeze(0).to(device)\n                    output1, (hidden1, cell1) = decoder.forward(input2, hidden1, cell1, temp)\n                    output2 = decoder.softmax(output1)\n                    top_probs, top_indices = output2.topk(beam_width)\n                    for j in range(beam_width):\n                        new_seq = sequence + [top_indices[0][j].item()]\n                        new_score = score - math.log(top_probs[0][j].item())\n                        new_beam.append((new_score, new_seq, hidden1, cell1))\n                new_beam.sort()\n                beam = new_beam[:beam_width]\n            predicted = torch.tensor([seq for score, seq, hidden1, cell1 in beam]).to(device)\n            predicted = predicted[:, 1:]  # remove <SOS> token\n            predicted = predicted.reshape(-1, predicted.size(2))\n            predictions = predicted.argmax(dim=1)\n            total_acc += accuracy(hin_word[x:x+batch_size].to(device), predictions, x)\n            loss = nn.CrossEntropyLoss(reduction='sum')(predicted, hin_word[x:x+batch_size].reshape(-1).to(device))\n            total_loss += loss.item()\n            del(predictions)\n            del(predicted)\n            del(hidden1)\n            del(cell1)\n        validation_loss = total_loss/(len(valdata)*val_max_hin_len)\n        validation_accuracy = (total_acc/len(valdata))*100\n","metadata":{"execution":{"iopub.status.busy":"2023-05-14T18:59:58.326934Z","iopub.execute_input":"2023-05-14T18:59:58.327429Z","iopub.status.idle":"2023-05-14T18:59:58.357969Z","shell.execute_reply.started":"2023-05-14T18:59:58.327387Z","shell.execute_reply":"2023-05-14T18:59:58.356664Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"batchsize,hidden_size,char_embed_size,no_of_layers,epochs,rnn = 512,256,256,8,10,'LSTM'\ntrain(batchsize,hidden_size,char_embed_size,no_of_layers,0.4,epochs,rnn)","metadata":{"execution":{"iopub.status.busy":"2023-05-14T18:59:59.332918Z","iopub.execute_input":"2023-05-14T18:59:59.333291Z","iopub.status.idle":"2023-05-14T19:00:56.475426Z","shell.execute_reply.started":"2023-05-14T18:59:59.333256Z","shell.execute_reply":"2023-05-14T19:00:56.473768Z"},"trusted":true},"execution_count":57,"outputs":[{"name":"stdout","text":"<bound method Module.parameters of Encoder(\n  (embedding): Embedding(29, 256)\n  (drop): Dropout(p=0.4, inplace=False)\n  (LSTM): LSTM(256, 256, num_layers=8, batch_first=True, bidirectional=True)\n  (RNN): RNN(256, 256, num_layers=8, batch_first=True, bidirectional=True)\n  (GRU): GRU(256, 256, num_layers=8, batch_first=True, bidirectional=True)\n)>\n<bound method Module.parameters of Decoder(\n  (embedding): Embedding(68, 256)\n  (drop): Dropout(p=0.4, inplace=False)\n  (LSTM): LSTM(768, 256, num_layers=8, batch_first=True)\n  (RNN): RNN(768, 256, num_layers=8, batch_first=True)\n  (GRU): GRU(768, 256, num_layers=8, batch_first=True)\n  (linear): Linear(in_features=256, out_features=68, bias=True)\n  (softmax): Softmax(dim=2)\n)>\n0\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_23/4223192400.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbatchsize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mchar_embed_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mno_of_layers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'LSTM'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mchar_embed_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mno_of_layers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_23/4143383398.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(batchsize, hidden_size, char_embed_size, no_of_layers, dropout, epochs, rnn)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mtraining_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_acc\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEvaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_eng_word\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_hin_word\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mchar_embed_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mno_of_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0mvalidation_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtempvalevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_eng_word\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_hin_word\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mchar_embed_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mno_of_layers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;31m#         wandb.log({'training_accuracy' : training_accuracy, 'validation_accuracy' : validation_accuracy,'training_loss' : training_loss, 'validation_loss' : validation_loss,'epoch':_+1})\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;31m#         if(_ >= epochs/2):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_23/594616461.py\u001b[0m in \u001b[0;36mtempvalevaluate\u001b[0;34m(attention, eng_word, hin_word, encoder, decoder, batch_size, hidden_size, char_embed_size, no_of_layers, beam_width)\u001b[0m\n\u001b[1;32m     35\u001b[0m                         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                     \u001b[0minput2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                     \u001b[0moutput1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m                     \u001b[0moutput2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                     \u001b[0mtop_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeam_width\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_23/2583504571.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hidden, cell, OGhidden)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mOGhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0membedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0membedded1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mOGhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mOGhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0membedded2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mcell1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 2. Expected size 1 but got size 512 for tensor number 1 in the list."],"ename":"RuntimeError","evalue":"Sizes of tensors must match except in dimension 2. Expected size 1 but got size 512 for tensor number 1 in the list.","output_type":"error"}]},{"cell_type":"code","source":"def valevaluate(attention,val_eng_word,val_hin_word,encoder,decoder,batchsize,hidden_size,char_embed_size,no_of_layers):\n    with torch.no_grad():\n        total_loss = 0\n        total_acc = 0\n        for x in range(0,len(valdata),batchsize):\n            loss = 0\n            input_tensor = val_eng_word[x:x+batchsize].to(device)\n#             en_hidden = torch.zeros(2*no_of_layers,batchsize,hidden_size).to(device)\n            if(input_tensor.size()[0] < batchsize):\n                break\n            en_hidden = torch.zeros(2*no_of_layers,batchsize,hidden_size).to(device)\n            en_cell = torch.zeros(2*no_of_layers,batchsize,hidden_size).to(device)\n            output,(hidden,cell) = encoder.forward(input_tensor,en_hidden,en_cell)\n            del(input_tensor)\n            del(en_hidden)\n            del(en_cell)\n            output = torch.split(output,[hidden_size,hidden_size],dim = 2)\n            output = torch.add(output[0],output[1])/2\n            input2 = []\n            for y in range(batchsize):\n                input2.append([0])\n            input2 = torch.tensor(input2).to(device)\n            hidden = hidden.resize(2,no_of_layers,batchsize,hidden_size)\n            hidden1 = torch.add(hidden[0],hidden[1])/2\n#             hidden1 = hidden[0]\n            cell = cell.resize(2,no_of_layers,batchsize,hidden_size)\n            cell1 = torch.add(cell[0],cell[1])/2\n#             cell1 = cell[0]\n            OGhidden = hidden1\n            predicted = []\n            predictions = []\n            if(attention == True):\n                temp = output\n            else:\n                temp = OGhidden\n            for i in range(val_max_hin_len):\n                output1,(hidden1,cell1) = decoder.forward(input2,hidden1,cell1,temp)\n                predicted.append(output1)\n                output2 = decoder.softmax(output1)\n                output3 = torch.argmax(output2,dim = 2)\n                predictions.append(output3)\n                input2 = output3\n            predicted = torch.cat(tuple(x for x in predicted),dim =1).to(device).resize(val_max_hin_len*batchsize,len(Hin_dict))\n            predictions = torch.cat(tuple(x for x in predictions),dim =1).to(device)\n            total_acc += accuracy(val_hin_word[x:x+batchsize].to(device),predictions,x)\n            loss  = nn.CrossEntropyLoss(reduction = 'sum')(predicted,val_hin_word[x:x+batchsize].reshape(-1).to(device))\n            with torch.no_grad():\n                total_loss += loss.item()\n        validation_loss = total_loss/(len(valdata)*val_max_hin_len)\n        validation_accuracy = (total_acc/len(valdata))*100\n        del(predictions)\n        del(predicted)\n        del(input2)\n        del(output1)\n        del(output2)\n        del(output3)\n        del(hidden1)\n        del(cell1)\n        del(OGhidden)\n        del(output)\n        del(cell)\n        return validation_loss,validation_accuracy","metadata":{"_uuid":"d62b8eec-4691-45b8-bf4c-801c67e17b69","_cell_guid":"d44fe09e-da6f-4612-848b-65db73dbfb18","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-05-17T15:31:43.899400Z","iopub.execute_input":"2023-05-17T15:31:43.901302Z","iopub.status.idle":"2023-05-17T15:31:43.923309Z","shell.execute_reply.started":"2023-05-17T15:31:43.901244Z","shell.execute_reply":"2023-05-17T15:31:43.921878Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"def attentiontrain(batchsize,hidden_size,char_embed_size,no_of_layers,dropout,epochs,rnn):\n    gc.collect()\n    torch.autograd.set_detect_anomaly(True)\n    encoder = Encoder(char_embed_size,hidden_size,no_of_layers,dropout,rnn).to(device)\n    decoder = Attention(char_embed_size,hidden_size,no_of_layers,dropout,batchsize,rnn).to(device)\n    print(encoder.parameters)\n    print(decoder.parameters)\n    opt_encoder = optim.Adam(encoder.parameters(),lr = 0.001)\n    opt_decoder  = optim.Adam(decoder.parameters(),lr = 0.001)\n    teacher_ratio = 0.5\n    for _ in range(epochs):\n        torch.cuda.empty_cache()\n        print(_)\n        total_loss = 0\n        total_acc = 0\n        for x in range(0,len(traindata),batchsize):\n            loss = 0\n            opt_encoder.zero_grad()\n            opt_decoder.zero_grad()\n            input_tensor = eng_word[x:x+batchsize].to(device)\n            en_hidden = torch.zeros(2*no_of_layers,batchsize,hidden_size).to(device)\n            en_cell = torch.zeros(2*no_of_layers,batchsize,hidden_size).to(device)\n            if(input_tensor.size()[0] < batchsize):\n                break\n            output,(hidden,cell) = encoder.forward(input_tensor,en_hidden,en_cell)\n            output = torch.split(output,[hidden_size,hidden_size],dim = 2)\n            output = torch.add(output[0],output[1])/2\n            input2 = []\n            for y in range(batchsize):\n                input2.append([0])\n            input2 = torch.tensor(input2).to(device)\n            hidden = hidden.resize(2,no_of_layers,batchsize,hidden_size)\n            hidden1 = torch.add(hidden[0],hidden[1])/2\n            cell = cell.resize(2,no_of_layers,batchsize,hidden_size)\n            cell1 = torch.add(cell[0],cell[1])/2\n            predicted = []\n            predictions = []\n#             use_teacher_forcing = True if random.random() < teacher_ratio else False\n            for i in range(max_hin_len):\n                use_teacher_forcing = True if random.random() < teacher_ratio else False\n                output1,(hidden1,cell1) = decoder.forward(input2,hidden1,cell1,output)\n                predicted.append(output1)\n                output2 = decoder.softmax(output1)\n                output3 = torch.argmax(output2,dim = 2)\n                predictions.append(output3)\n                if(use_teacher_forcing):\n                    input2 = hin_word[x:x+batchsize,i].to(device).resize(batchsize,1)\n                else:\n                    input2 = hin_word[x:x+batchsize,i].to(device).resize(batchsize,1)\n\n#             if use_teacher_forcing:\n#                 for i in range(max_hin_len):\n#                     output1,(hidden1,cell1) = decoder.forward(input2,hidden1,cell1,output)\n#                     predicted.append(output1)\n#                     output2 = decoder.softmax(output1)\n#                     output3 = torch.argmax(output2,dim = 2)\n#                     predictions.append(output3)\n#                     input2 = hin_word[x:x+batchsize,i].to(device).resize(batchsize,1)\n#             else:\n#                 for i in range(max_hin_len):\n#                     output1,(hidden1,cell1) = decoder.forward(input2,hidden1,cell1,output)\n#                     predicted.append(output1)\n#                     output2 = decoder.softmax(output1)\n#                     output3 = torch.argmax(output2,dim = 2)\n#                     predictions.append(output3)\n#                     input2 = output3\n            \n            predicted = torch.cat(tuple(x for x in predicted),dim =1).to(device).resize(max_hin_len*batchsize,len(Hin_dict))\n            predictions = torch.cat(tuple(x for x in predictions),dim =1).to(device)\n            total_acc += accuracy(hin_word[x:x+batchsize].to(device),predictions,x)\n            loss  = nn.CrossEntropyLoss(reduction = 'sum')(predicted,hin_word[x:x+batchsize].reshape(-1).to(device))\n            with torch.no_grad():\n                total_loss += loss.item()\n            loss.backward(retain_graph = True)\n            torch.nn.utils.clip_grad_norm_(encoder.parameters(),max_norm = 1)\n            torch.nn.utils.clip_grad_norm_(decoder.parameters(),max_norm = 1)\n            opt_encoder.step()\n            opt_decoder.step()\n        del(input_tensor)\n        del(en_hidden)\n        del(en_cell)\n        del(predictions)\n        del(predicted)\n        del(input2)\n        del(output1)\n        del(output2)\n        del(output3)\n        del(hidden)\n        del(hidden1)\n        del(cell1)\n        del(output)\n        del(cell)\n        training_loss = total_loss/(51200*max_hin_len)\n        training_accuracy = total_acc/512\n        test_loss,test_accuracy = Evaluate(True,test_eng_word,test_hin_word,encoder,decoder,batchsize,hidden_size,char_embed_size,no_of_layers)\n        validation_loss,validation_accuracy = valevaluate(True,val_eng_word,val_hin_word,encoder,decoder,batchsize,hidden_size,char_embed_size,no_of_layers)\n        wandb.log({'training_accuracy' : training_accuracy, 'validation_accuracy' : validation_accuracy,'training_loss' : training_loss, 'validation_loss' : validation_loss,'epoch':_+1})\n#         if(_ >= epochs/2):\n#             teacher_ratio = 0\n#         teacher_ratio /= 2\n    return encoder,decoder","metadata":{"_uuid":"4dcdf24e-2a6d-436a-b099-cbfd70d0588c","_cell_guid":"6b181c70-31ae-4f4d-833f-dbdf4f5be26d","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-05-17T15:58:33.524498Z","iopub.execute_input":"2023-05-17T15:58:33.524893Z","iopub.status.idle":"2023-05-17T15:58:33.558615Z","shell.execute_reply.started":"2023-05-17T15:58:33.524854Z","shell.execute_reply":"2023-05-17T15:58:33.557209Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"import gc\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-05-17T15:31:51.735639Z","iopub.execute_input":"2023-05-17T15:31:51.736897Z","iopub.status.idle":"2023-05-17T15:31:51.858862Z","shell.execute_reply.started":"2023-05-17T15:31:51.736842Z","shell.execute_reply":"2023-05-17T15:31:51.857474Z"},"trusted":true},"execution_count":39,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"23"},"metadata":{}}]},{"cell_type":"code","source":"# batchsize,hidden_size,char_embed_size,no_of_layers,dropout,epochs,rnn\n# train(256,512,256,2,0.3,10,'LSTM')","metadata":{"execution":{"iopub.status.busy":"2023-05-15T14:23:52.301953Z","iopub.execute_input":"2023-05-15T14:23:52.302999Z","iopub.status.idle":"2023-05-15T14:23:52.308425Z","shell.execute_reply.started":"2023-05-15T14:23:52.302949Z","shell.execute_reply":"2023-05-15T14:23:52.307171Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"def train(batchsize,hidden_size,char_embed_size,no_of_layers,dropout,epochs,rnn):\n    gc.collect()\n    torch.autograd.set_detect_anomaly(True)\n    encoder = Encoder(char_embed_size,hidden_size,no_of_layers,dropout,rnn).to(device)\n    decoder = Decoder(char_embed_size,hidden_size,no_of_layers,dropout,batchsize,rnn).to(device)\n    print(encoder.parameters)\n    print(decoder.parameters)\n    opt_encoder = optim.Adam(encoder.parameters(),lr = 0.001)\n    opt_decoder  = optim.Adam(decoder.parameters(),lr = 0.001)\n    teacher_ratio = 0.5\n#     en_hidden = torch.randn(2*no_of_layers,batchsize,hidden_size).to(device)\n    for _ in range(epochs):\n        print(_)\n        total_loss = 0\n        total_acc = 0\n        for x in range(0,len(traindata),batchsize):\n            loss = 0\n            opt_encoder.zero_grad()\n            opt_decoder.zero_grad()\n            input_tensor = eng_word[x:x+batchsize].to(device)\n            en_hidden = torch.zeros(2*no_of_layers,batchsize,hidden_size).to(device)\n            en_cell = torch.zeros(2*no_of_layers,batchsize,hidden_size).to(device)\n            if(input_tensor.size()[0] < batchsize):\n                break\n            output,(hidden,cell) = encoder.forward(input_tensor,en_hidden,en_cell)\n            del(en_hidden)\n            del(en_cell)\n            del(input_tensor)\n            input2 = []\n            for y in range(batchsize):\n                input2.append([0])\n            input2 = torch.tensor(input2).to(device)\n            hidden = hidden.resize(2,no_of_layers,batchsize,hidden_size)\n            cell = cell.resize(2,no_of_layers,batchsize,hidden_size)\n            hidden1 = torch.add(hidden[0],hidden[1])/2\n            cell1 = torch.add(cell[0],cell[1])/2\n            OGhidden = hidden1\n            predicted = []\n            predictions = []\n            use_teacher_forcing = True if random.random() < teacher_ratio else False\n            if use_teacher_forcing:\n                for i in range(max_hin_len):\n                    output1,(hidden1,cell1) = decoder.forward(input2,hidden1,cell1,OGhidden)\n                    predicted.append(output1)\n                    output2 = decoder.softmax(output1)\n                    output3 = torch.argmax(output2,dim = 2)\n                    predictions.append(output3)\n                    input2 = hin_word[x:x+batchsize,i].to(device).resize(batchsize,1)\n            else:\n                for i in range(max_hin_len):\n                    output1,(hidden1,cell1) = decoder.forward(input2,hidden1,cell1,OGhidden)\n                    predicted.append(output1)\n                    output2 = decoder.softmax(output1)\n                    output3 = torch.argmax(output2,dim = 2)\n                    predictions.append(output3)\n                    input2 = output3\n            predicted = torch.cat(tuple(x for x in predicted),dim =1).to(device).resize(max_hin_len*batchsize,len(Hin_dict))\n            predictions = torch.cat(tuple(x for x in predictions),dim =1).to(device)\n            total_acc += accuracy(hin_word[x:x+batchsize].to(device),predictions,x)\n            loss  = nn.CrossEntropyLoss(reduction = 'sum')(predicted,hin_word[x:x+batchsize].reshape(-1).to(device))\n            with torch.no_grad():\n                total_loss += loss.item()\n            loss.backward(retain_graph = True)\n            torch.nn.utils.clip_grad_norm_(encoder.parameters(),max_norm = 1)\n            torch.nn.utils.clip_grad_norm_(decoder.parameters(),max_norm = 1)\n            opt_encoder.step()\n            opt_decoder.step()\n        del(predictions)\n        del(predicted)\n        del(input2)\n        del(output1)\n        del(output2)\n        del(output3)\n        del(hidden1)\n        del(cell1)\n        del(OGhidden)\n        del(output)\n        del(cell)\n        training_loss = total_loss/(51200*max_hin_len)\n        training_accuracy = total_acc/512\n        test_loss,test_accuracy = Evaluate(False,test_eng_word,test_hin_word,encoder,decoder,batchsize,hidden_size,char_embed_size,no_of_layers)\n        validation_loss,validation_accuracy = tempvalevaluate(False,val_eng_word,val_hin_word,encoder,decoder,batchsize,hidden_size,char_embed_size,no_of_layers,2)\n#         wandb.log({'training_accuracy' : training_accuracy, 'validation_accuracy' : validation_accuracy,'training_loss' : training_loss, 'validation_loss' : validation_loss,'epoch':_+1})\n#         if(_ >= epochs/2):\n#             teacher_ratio = 0\n    return encoder,decoder","metadata":{"_uuid":"42b45bb3-0b49-4039-88f5-c2abb3a4b027","_cell_guid":"e6f86775-000d-4c9a-b2f0-a23a882897b8","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-05-17T15:31:55.740895Z","iopub.execute_input":"2023-05-17T15:31:55.741356Z","iopub.status.idle":"2023-05-17T15:31:55.772975Z","shell.execute_reply.started":"2023-05-17T15:31:55.741314Z","shell.execute_reply":"2023-05-17T15:31:55.771222Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"def getword(characters):\n    return \"\".join(characters)","metadata":{"_uuid":"47a9eeac-d4cb-4ec3-ab49-aa04ba088bb0","_cell_guid":"51e131fd-e98c-433c-ae81-14fe4af3c714","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-05-17T15:31:56.748593Z","iopub.execute_input":"2023-05-17T15:31:56.749373Z","iopub.status.idle":"2023-05-17T15:31:56.754447Z","shell.execute_reply.started":"2023-05-17T15:31:56.749331Z","shell.execute_reply":"2023-05-17T15:31:56.753300Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"def accuracy(target,predictions,flag):\n    total = 0\n#     if(flag == 0):\n#         for x in range(1):\n#             print(getword([reverse_Hin[x.item()] for x in target[x]]))\n#             print(getword([reverse_Hin[x.item()] for x in predictions[x]]))\n    for x in range(len(target)):\n        if(torch.equal(target[x],predictions[x])):\n            total += 1\n    return total","metadata":{"_uuid":"aa6ef9a8-f99b-4ac7-9a13-2ddbfd87c5e4","_cell_guid":"75ddf732-5e43-4f84-9d70-ee30c36968b3","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-05-17T15:31:57.601129Z","iopub.execute_input":"2023-05-17T15:31:57.601542Z","iopub.status.idle":"2023-05-17T15:31:57.610390Z","shell.execute_reply.started":"2023-05-17T15:31:57.601504Z","shell.execute_reply":"2023-05-17T15:31:57.609032Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"import wandb","metadata":{"execution":{"iopub.status.busy":"2023-05-17T15:32:00.367584Z","iopub.execute_input":"2023-05-17T15:32:00.368813Z","iopub.status.idle":"2023-05-17T15:32:00.907288Z","shell.execute_reply.started":"2023-05-17T15:32:00.368759Z","shell.execute_reply":"2023-05-17T15:32:00.906053Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"wandb.login()","metadata":{"_uuid":"3afa4535-f7b1-40fd-b2e3-ace8fcb2e5d4","_cell_guid":"b5b3bab1-edd2-4297-9934-efba5e3020e6","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-05-17T15:32:01.242149Z","iopub.execute_input":"2023-05-17T15:32:01.243382Z","iopub.status.idle":"2023-05-17T15:32:12.263933Z","shell.execute_reply.started":"2023-05-17T15:32:01.243328Z","shell.execute_reply":"2023-05-17T15:32:12.262771Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"# batchsize,hidden_size,char_embed_size,no_of_layers,epochs,rnn = 1024,256,256,8,10,'LSTM'\n# train(batchsize,hidden_size,char_embed_size,no_of_layers,0.4,epochs,rnn)","metadata":{"execution":{"iopub.status.busy":"2023-05-14T18:35:30.523558Z","iopub.execute_input":"2023-05-14T18:35:30.523978Z","iopub.status.idle":"2023-05-14T18:36:15.304203Z","shell.execute_reply.started":"2023-05-14T18:35:30.523930Z","shell.execute_reply":"2023-05-14T18:36:15.302514Z"},"trusted":true},"execution_count":67,"outputs":[{"name":"stdout","text":"<bound method Module.parameters of Encoder(\n  (embedding): Embedding(29, 256)\n  (drop): Dropout(p=0.4, inplace=False)\n  (LSTM): LSTM(256, 256, num_layers=8, batch_first=True, bidirectional=True)\n  (RNN): RNN(256, 256, num_layers=8, batch_first=True, bidirectional=True)\n  (GRU): GRU(256, 256, num_layers=8, batch_first=True, bidirectional=True)\n)>\n<bound method Module.parameters of Decoder(\n  (embedding): Embedding(68, 256)\n  (drop): Dropout(p=0.4, inplace=False)\n  (LSTM): LSTM(768, 256, num_layers=8, batch_first=True)\n  (RNN): RNN(768, 256, num_layers=8, batch_first=True)\n  (GRU): GRU(768, 256, num_layers=8, batch_first=True)\n  (linear): Linear(in_features=256, out_features=68, bias=True)\n  (softmax): Softmax(dim=2)\n)>\n0\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_23/2859204228.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbatchsize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mchar_embed_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mno_of_layers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'LSTM'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mchar_embed_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mno_of_layers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_23/4143383398.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(batchsize, hidden_size, char_embed_size, no_of_layers, dropout, epochs, rnn)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mtraining_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_acc\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEvaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_eng_word\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_hin_word\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mchar_embed_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mno_of_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0mvalidation_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtempvalevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_eng_word\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_hin_word\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mchar_embed_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mno_of_layers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;31m#         wandb.log({'training_accuracy' : training_accuracy, 'validation_accuracy' : validation_accuracy,'training_loss' : training_loss, 'validation_loss' : validation_loss,'epoch':_+1})\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;31m#         if(_ >= epochs/2):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_23/2740656503.py\u001b[0m in \u001b[0;36mtempvalevaluate\u001b[0;34m(attention, eng_word, hin_word, encoder, decoder, batch_size, hidden_size, char_embed_size, no_of_layers, beam_width)\u001b[0m\n\u001b[1;32m     42\u001b[0m                     \u001b[0mtop_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeam_width\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeam_width\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m                         \u001b[0mnew_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msequence\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtop_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m                         \u001b[0mnew_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_probs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                         \u001b[0mnew_beam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"],"ename":"ValueError","evalue":"only one element tensors can be converted to Python scalars","output_type":"error"}]},{"cell_type":"code","source":"def withoutattention():\n    wandb.init(project='CS6910_DLAssignment3')\n    config = wandb.config\n    wandb.run.name = \"withoutattention_cell_type_{}_bidirec_{}_layers_{}_batchsize_{}_hidden_{}\".format(config.cell_type,config.bidirectional,config.no_of_layers,config.batchsize,config.hidden_size)\n    hidden_size = config.hidden_size\n    char_embed_size = config.input_embedding_size\n    no_of_layers = config.no_of_layers\n    epochs = config.epochs\n    batchsize = config.batchsize\n    dropout = config.dropout\n    rnn = config.cell_type\n    Encoder1,Decoder1 = train(batchsize,hidden_size,char_embed_size,no_of_layers,dropout,epochs,rnn)\n    free_gpu_cache()","metadata":{"execution":{"iopub.status.busy":"2023-05-17T15:32:15.523393Z","iopub.execute_input":"2023-05-17T15:32:15.523795Z","iopub.status.idle":"2023-05-17T15:32:15.534480Z","shell.execute_reply.started":"2023-05-17T15:32:15.523755Z","shell.execute_reply":"2023-05-17T15:32:15.533013Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"def main():\n    wandb.init(project='CS6910_DLAssignment3')\n    config = wandb.config\n    wandb.run.name = \"attention_cell_type_{}_bidirec_{}_layers_{}_batchsize_{}_hidden_{}\".format(config.cell_type,config.bidirectional,config.no_of_layers,config.batchsize,config.hidden_size)\n    hidden_size = config.hidden_size\n    char_embed_size = config.input_embedding_size\n    no_of_layers = config.no_of_layers\n    epochs = config.epochs\n    batchsize = config.batchsize\n    dropout = config.dropout\n    rnn = config.cell_type\n    Encoder1,Decoder1 = attentiontrain(batchsize,hidden_size,char_embed_size,no_of_layers,dropout,epochs,rnn)\n    free_gpu_cache()","metadata":{"_uuid":"709ded71-f859-4e48-8b42-94fd3c2845d5","_cell_guid":"78cee7f5-0f06-4eae-a2fb-2e4355f25a9e","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-05-17T15:32:18.597918Z","iopub.execute_input":"2023-05-17T15:32:18.598678Z","iopub.status.idle":"2023-05-17T15:32:18.607097Z","shell.execute_reply.started":"2023-05-17T15:32:18.598634Z","shell.execute_reply":"2023-05-17T15:32:18.605793Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"!pip install GPUtil\n\nimport torch\nfrom GPUtil import showUtilization as gpu_usage\nfrom numba import cuda\n\ndef free_gpu_cache():\n    print(\"Initial GPU Usage\")\n    gpu_usage()                             \n\n    torch.cuda.empty_cache()\n\n    cuda.select_device(0)\n    cuda.close()\n    cuda.select_device(0)\n\n    print(\"GPU Usage after emptying the cache\")\n    gpu_usage()","metadata":{"execution":{"iopub.status.busy":"2023-05-17T15:32:22.028172Z","iopub.execute_input":"2023-05-17T15:32:22.028537Z","iopub.status.idle":"2023-05-17T15:32:37.969112Z","shell.execute_reply.started":"2023-05-17T15:32:22.028505Z","shell.execute_reply":"2023-05-17T15:32:37.967978Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"Collecting GPUtil\n  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hBuilding wheels for collected packages: GPUtil\n  Building wheel for GPUtil (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for GPUtil: filename=GPUtil-1.4.0-py3-none-any.whl size=7409 sha256=0d748e0667fd19faa1842a901a249bcd83a15a435064959e91d1f68c25d7280e\n  Stored in directory: /root/.cache/pip/wheels/b1/e7/99/2b32600270cf23194c9860f029d3d5db075f250bc39028c045\nSuccessfully built GPUtil\nInstalling collected packages: GPUtil\nSuccessfully installed GPUtil-1.4.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"free_gpu_cache()","metadata":{"execution":{"iopub.status.busy":"2023-05-14T18:19:06.351237Z","iopub.execute_input":"2023-05-14T18:19:06.351674Z","iopub.status.idle":"2023-05-14T18:19:06.680510Z","shell.execute_reply.started":"2023-05-14T18:19:06.351633Z","shell.execute_reply":"2023-05-14T18:19:06.678327Z"},"trusted":true},"execution_count":57,"outputs":[{"name":"stdout","text":"Initial GPU Usage\n| ID | GPU | MEM |\n------------------\n|  0 |  0% |  0% |\n|  1 |  0% |  0% |\nGPU Usage after emptying the cache\n| ID | GPU | MEM |\n------------------\n|  0 |  4% |  1% |\n|  1 |  0% |  0% |\n","output_type":"stream"}]},{"cell_type":"code","source":"sweep_configuration = {\n    'method' : 'bayes',\n    'metric' : { 'goal' : 'maximize',\n    'name' : 'validation_accuracy'},\n    'parameters':{\n        'batchsize' : {'values' : [256]},\n        'input_embedding_size' : {'values' : [512]},\n        'no_of_layers' : {'values' : [2]},\n        'hidden_size' : {'values' : [1024]},\n        'cell_type' : {'values' : ['LSTM']},\n        'bidirectional' : {'values' : ['Yes']},\n        'dropout' : {'values' : [0.3]},\n        'epochs' : {'values' : [30]}\n    }\n}\nsweep_id = wandb.sweep(sweep = sweep_configuration,project = 'CS6910_DLAssignment3')\nwandb.agent(sweep_id,function=main,count = 1)","metadata":{"_uuid":"89e211a6-9bad-4638-976b-16543ea4502b","_cell_guid":"837ccbac-da19-435e-a773-0f630c4918e3","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-05-17T15:58:40.240265Z","iopub.execute_input":"2023-05-17T15:58:40.240699Z","iopub.status.idle":"2023-05-17T17:18:52.326408Z","shell.execute_reply.started":"2023-05-17T15:58:40.240662Z","shell.execute_reply":"2023-05-17T17:18:52.325233Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"Create sweep with ID: xf69w1mf\nSweep URL: https://wandb.ai/cs22m031/CS6910_DLAssignment3/sweeps/xf69w1mf\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: woa4lgy1 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatchsize: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: Yes\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 1024\n\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_embedding_size: 512\n\u001b[34m\u001b[1mwandb\u001b[0m: \tno_of_layers: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.15.2 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.14.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20230517_155844-woa4lgy1</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs22m031/CS6910_DLAssignment3/runs/woa4lgy1' target=\"_blank\">soft-sweep-1</a></strong> to <a href='https://wandb.ai/cs22m031/CS6910_DLAssignment3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs22m031/CS6910_DLAssignment3/sweeps/xf69w1mf' target=\"_blank\">https://wandb.ai/cs22m031/CS6910_DLAssignment3/sweeps/xf69w1mf</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs22m031/CS6910_DLAssignment3' target=\"_blank\">https://wandb.ai/cs22m031/CS6910_DLAssignment3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs22m031/CS6910_DLAssignment3/sweeps/xf69w1mf' target=\"_blank\">https://wandb.ai/cs22m031/CS6910_DLAssignment3/sweeps/xf69w1mf</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs22m031/CS6910_DLAssignment3/runs/woa4lgy1' target=\"_blank\">https://wandb.ai/cs22m031/CS6910_DLAssignment3/runs/woa4lgy1</a>"},"metadata":{}},{"name":"stdout","text":"<bound method Module.parameters of Encoder(\n  (embedding): Embedding(29, 512)\n  (drop): Dropout(p=0.3, inplace=False)\n  (LSTM): LSTM(512, 1024, num_layers=2, batch_first=True, bidirectional=True)\n  (RNN): RNN(512, 1024, num_layers=2, batch_first=True, bidirectional=True)\n  (GRU): GRU(512, 1024, num_layers=2, batch_first=True, bidirectional=True)\n)>\n<bound method Module.parameters of Attention(\n  (embedding): Embedding(68, 512)\n  (drop): Dropout(p=0.3, inplace=False)\n  (U): Linear(in_features=1024, out_features=1024, bias=False)\n  (W): Linear(in_features=1024, out_features=1024, bias=False)\n  (V): Linear(in_features=1024, out_features=1, bias=False)\n  (LSTM): LSTM(1536, 1024, num_layers=2, batch_first=True)\n  (RNN): RNN(1536, 1024, num_layers=2, batch_first=True)\n  (GRU): GRU(1536, 1024, num_layers=2, batch_first=True)\n  (linear): Linear(in_features=1024, out_features=68, bias=True)\n  (softmax): Softmax(dim=2)\n)>\n0\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:760: UserWarning: non-inplace resize is deprecated\n  warnings.warn(\"non-inplace resize is deprecated\")\n/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","output_type":"stream"},{"name":"stdout","text":"1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n","output_type":"stream"}]},{"cell_type":"code","source":"sweep_configuration = {\n    'method' : 'bayes',\n    'metric' : { 'goal' : 'maximize',\n    'name' : 'validation_accuracy'},\n    'parameters':{\n        'batchsize' : {'values' : [64,128,256,512]},\n        'input_embedding_size' : {'values' : [128,256,512,1024]},\n        'no_of_layers' : {'values' : [1,2,3,4]},\n        'hidden_size' : {'values' : [128,256,512,1024]},\n        'cell_type' : {'values' : ['LSTM']},\n        'bidirectional' : {'values' : ['Yes']},\n        'dropout' : {'values' : [0.3,0.4,0.5]},\n        'epochs' : {'values' : [10,20,30]}\n    }\n}\nsweep_id = wandb.sweep(sweep = sweep_configuration,project = 'CS6910_DLAssignment3')\nwandb.agent(sweep_id,function=main,count = 20)","metadata":{"_uuid":"ae89cd33-f93c-4bd8-89b3-8408de8dbced","_cell_guid":"72f27865-096a-4231-96ea-aa2a932aea33","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-05-17T17:19:02.474251Z","iopub.execute_input":"2023-05-17T17:19:02.475126Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Create sweep with ID: 15q3jr0g\nSweep URL: https://wandb.ai/cs22m031/CS6910_DLAssignment3/sweeps/15q3jr0g\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: cew7rq2i with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatchsize: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: Yes\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 1024\n\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_embedding_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tno_of_layers: 4\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.15.2 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.14.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20230517_171906-cew7rq2i</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs22m031/CS6910_DLAssignment3/runs/cew7rq2i' target=\"_blank\">cerulean-sweep-1</a></strong> to <a href='https://wandb.ai/cs22m031/CS6910_DLAssignment3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs22m031/CS6910_DLAssignment3/sweeps/15q3jr0g' target=\"_blank\">https://wandb.ai/cs22m031/CS6910_DLAssignment3/sweeps/15q3jr0g</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs22m031/CS6910_DLAssignment3' target=\"_blank\">https://wandb.ai/cs22m031/CS6910_DLAssignment3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs22m031/CS6910_DLAssignment3/sweeps/15q3jr0g' target=\"_blank\">https://wandb.ai/cs22m031/CS6910_DLAssignment3/sweeps/15q3jr0g</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs22m031/CS6910_DLAssignment3/runs/cew7rq2i' target=\"_blank\">https://wandb.ai/cs22m031/CS6910_DLAssignment3/runs/cew7rq2i</a>"},"metadata":{}},{"name":"stdout","text":"<bound method Module.parameters of Encoder(\n  (embedding): Embedding(29, 256)\n  (drop): Dropout(p=0.3, inplace=False)\n  (LSTM): LSTM(256, 1024, num_layers=4, batch_first=True, bidirectional=True)\n  (RNN): RNN(256, 1024, num_layers=4, batch_first=True, bidirectional=True)\n  (GRU): GRU(256, 1024, num_layers=4, batch_first=True, bidirectional=True)\n)>\n<bound method Module.parameters of Attention(\n  (embedding): Embedding(68, 256)\n  (drop): Dropout(p=0.3, inplace=False)\n  (U): Linear(in_features=1024, out_features=1024, bias=False)\n  (W): Linear(in_features=1024, out_features=1024, bias=False)\n  (V): Linear(in_features=1024, out_features=1, bias=False)\n  (LSTM): LSTM(1280, 1024, num_layers=4, batch_first=True)\n  (RNN): RNN(1280, 1024, num_layers=4, batch_first=True)\n  (GRU): GRU(1280, 1024, num_layers=4, batch_first=True)\n  (linear): Linear(in_features=1024, out_features=68, bias=True)\n  (softmax): Softmax(dim=2)\n)>\n0\n1\n2\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"_uuid":"f1988f75-75d5-4273-b207-2ad3a36da6a3","_cell_guid":"47923dfe-3b00-444a-adb7-3bd8d1bafe34","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_uuid":"5d3dbcec-dd88-418d-9e38-1f3d984a8109","_cell_guid":"f9bce234-8a8e-42d1-92ac-4e146bd9cf51","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}