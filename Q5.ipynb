{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"_cell_guid":"652f4112-e78d-4fd8-b5a1-554a4359e84a","_uuid":"3e6633a7-d372-4e06-9c47-feaaf1b1394a","trusted":true},"source":["### Importing necessary modules"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"08e258d1-96c7-47d7-a1e1-cf659adcf195","_uuid":"9179396e-8ac7-4a6d-aef4-f4d26400cc60","collapsed":false,"execution":{"iopub.execute_input":"2023-05-21T09:44:44.474391Z","iopub.status.busy":"2023-05-21T09:44:44.473965Z","iopub.status.idle":"2023-05-21T09:44:44.549080Z","shell.execute_reply":"2023-05-21T09:44:44.548190Z","shell.execute_reply.started":"2023-05-21T09:44:44.474362Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c9291a6d-bfc1-43d8-8093-9019b4a1fffb","_uuid":"b6dbf7ab-c1e1-4f2f-9d24-0cc7374c3b3a","collapsed":false,"execution":{"iopub.execute_input":"2023-05-21T09:44:44.655504Z","iopub.status.busy":"2023-05-21T09:44:44.655229Z","iopub.status.idle":"2023-05-21T09:44:48.471923Z","shell.execute_reply":"2023-05-21T09:44:48.470990Z","shell.execute_reply.started":"2023-05-21T09:44:44.655474Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["import torch\n","from torch.utils.data import DataLoader\n","import matplotlib.pyplot as plt\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch import optim\n","import gc\n","import random\n","import numpy as np \n","import pandas as pd\n","import seaborn as sns\n","from matplotlib.font_manager import FontProperties"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"97a5f498-be55-4951-8951-f651542236e4","_uuid":"fd828dff-7416-4712-80f4-2b265aea5890","collapsed":false,"execution":{"iopub.execute_input":"2023-05-21T09:44:48.474517Z","iopub.status.busy":"2023-05-21T09:44:48.473966Z","iopub.status.idle":"2023-05-21T09:44:48.543742Z","shell.execute_reply":"2023-05-21T09:44:48.542702Z","shell.execute_reply.started":"2023-05-21T09:44:48.474483Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["if torch.cuda.is_available():\n","    # If CUDA is available, use a CUDA device\n","    device = torch.device(\"cuda\")\n","else:\n","    # If CUDA is not available, use the CPU\n","    device = torch.device(\"cpu\")"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ff06e21c-b914-4b1f-bff6-1f9fb95453b1","_uuid":"068157e7-e2d5-478d-aa16-c5af25ee000f","collapsed":false,"execution":{"iopub.execute_input":"2023-05-21T09:44:48.547280Z","iopub.status.busy":"2023-05-21T09:44:48.546909Z","iopub.status.idle":"2023-05-21T09:44:48.558480Z","shell.execute_reply":"2023-05-21T09:44:48.557610Z","shell.execute_reply.started":"2023-05-21T09:44:48.547252Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["device"]},{"attachments":{},"cell_type":"markdown","metadata":{"_cell_guid":"4121ff99-b739-41df-a814-28d163a10130","_uuid":"00e0122f-84f5-4318-a24d-384d084f9a83","trusted":true},"source":["### Preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f513202b-a035-43d8-9938-b2c15b8c99f8","_uuid":"fb959326-562d-4060-89cb-b8aa1ff6e07a","collapsed":false,"execution":{"iopub.execute_input":"2023-05-21T09:44:48.561494Z","iopub.status.busy":"2023-05-21T09:44:48.561093Z","iopub.status.idle":"2023-05-21T09:44:48.661143Z","shell.execute_reply":"2023-05-21T09:44:48.660217Z","shell.execute_reply.started":"2023-05-21T09:44:48.561463Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["traindata = pd.read_csv('/kaggle/input/aksharantar-sampled/aksharantar_sampled/hin/hin_train.csv',names= ['English','Hindi'],header = None)"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6d137a7a-7d86-4e09-8198-5872c86c952d","_uuid":"f5257286-4a2f-4d09-8b53-e942174e0e77","collapsed":false,"execution":{"iopub.execute_input":"2023-05-21T09:44:48.663683Z","iopub.status.busy":"2023-05-21T09:44:48.662893Z","iopub.status.idle":"2023-05-21T09:44:48.680868Z","shell.execute_reply":"2023-05-21T09:44:48.680000Z","shell.execute_reply.started":"2023-05-21T09:44:48.663647Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["testdata = pd.read_csv('/kaggle/input/aksharantar-sampled/aksharantar_sampled/hin/hin_test.csv',names = ['English','Hindi'],header = None)"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"17443629-339a-4770-bc5d-f20da9022437","_uuid":"9b3a79cb-4abc-4fa8-a1ba-7b23c223d506","collapsed":false,"execution":{"iopub.execute_input":"2023-05-21T09:44:48.682733Z","iopub.status.busy":"2023-05-21T09:44:48.682400Z","iopub.status.idle":"2023-05-21T09:44:48.696646Z","shell.execute_reply":"2023-05-21T09:44:48.695815Z","shell.execute_reply.started":"2023-05-21T09:44:48.682701Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["valdata = pd.read_csv('/kaggle/input/aksharantar-sampled/aksharantar_sampled/hin/hin_valid.csv',names = ['English','Hindi'],header = None)"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e300ed74-a8e6-40e8-b426-538436f2ab53","_uuid":"5721b879-1422-44af-85ce-234817e24108","collapsed":false,"execution":{"iopub.execute_input":"2023-05-21T09:44:48.698447Z","iopub.status.busy":"2023-05-21T09:44:48.698128Z","iopub.status.idle":"2023-05-21T09:44:48.715671Z","shell.execute_reply":"2023-05-21T09:44:48.714589Z","shell.execute_reply.started":"2023-05-21T09:44:48.698416Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["traindata"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c340e0b9-204c-4a30-a27a-8808bfffbb8c","_uuid":"d7b867e6-efe9-4178-8e62-14db9d67d7e7","collapsed":false,"execution":{"iopub.execute_input":"2023-05-21T09:44:48.717899Z","iopub.status.busy":"2023-05-21T09:44:48.716931Z","iopub.status.idle":"2023-05-21T09:44:48.722870Z","shell.execute_reply":"2023-05-21T09:44:48.721908Z","shell.execute_reply.started":"2023-05-21T09:44:48.717863Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["def tokenize(word):\n","    tokens = []\n","    for x in word:\n","        tokens.append(x)\n","    return tokens"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"70c6ae52-ede3-45ab-ae7b-3157ded59954","_uuid":"8e1eaba3-861f-45a6-b6c1-9a0fa23a2fce","collapsed":false,"execution":{"iopub.execute_input":"2023-05-21T09:44:48.725249Z","iopub.status.busy":"2023-05-21T09:44:48.724371Z","iopub.status.idle":"2023-05-21T09:44:48.733951Z","shell.execute_reply":"2023-05-21T09:44:48.732793Z","shell.execute_reply.started":"2023-05-21T09:44:48.725216Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["max_eng_len = 0\n","max_hin_len = 0\n","test_max_eng_len = 0\n","test_max_hin_len = 0\n","val_max_eng_len = 0\n","val_max_hin_len = 0"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"184ebbf6-3501-47db-92c8-e14ad49a78ac","_uuid":"595db3bc-9b8c-491d-8bbc-3aa694a7b066","collapsed":false,"execution":{"iopub.execute_input":"2023-05-21T09:44:48.738629Z","iopub.status.busy":"2023-05-21T09:44:48.738378Z","iopub.status.idle":"2023-05-21T09:44:48.925707Z","shell.execute_reply":"2023-05-21T09:44:48.924680Z","shell.execute_reply.started":"2023-05-21T09:44:48.738606Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["for x in range(len(testdata)):\n","    temp = 0\n","    for y in testdata.iloc[x]['English']:\n","        temp+=1\n","    test_max_eng_len = max(test_max_eng_len,temp)\n","print(test_max_eng_len)"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"587d6de4-71a8-46ac-98a8-d73643030032","_uuid":"d9817973-c648-4674-9569-740a5c9e35b5","collapsed":false,"execution":{"iopub.execute_input":"2023-05-21T09:44:48.927673Z","iopub.status.busy":"2023-05-21T09:44:48.926891Z","iopub.status.idle":"2023-05-21T09:44:49.112976Z","shell.execute_reply":"2023-05-21T09:44:49.112076Z","shell.execute_reply.started":"2023-05-21T09:44:48.927638Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["for x in range(len(testdata)):\n","    temp = 0\n","    for y in testdata.iloc[x]['Hindi']:\n","        temp +=1\n","    test_max_hin_len = max(test_max_hin_len,temp)\n","print(test_max_hin_len)"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"697e8f39-8a79-4f3a-81fb-eacab103c1ef","_uuid":"8382bad8-7b83-4298-8d76-f20e69045e2b","collapsed":false,"execution":{"iopub.execute_input":"2023-05-21T09:44:49.114873Z","iopub.status.busy":"2023-05-21T09:44:49.114349Z","iopub.status.idle":"2023-05-21T09:44:49.295092Z","shell.execute_reply":"2023-05-21T09:44:49.294089Z","shell.execute_reply.started":"2023-05-21T09:44:49.114839Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["for x in range(len(valdata)):\n","    temp = 0\n","    for y in valdata.iloc[x]['English']:\n","        temp+=1\n","    val_max_eng_len = max(val_max_eng_len,temp)\n","print(val_max_eng_len)"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a19f98a4-630d-4d58-842a-b378901ebfb3","_uuid":"7554564d-c2c7-45bb-afda-526a6bee82e1","collapsed":false,"execution":{"iopub.execute_input":"2023-05-21T09:44:49.296752Z","iopub.status.busy":"2023-05-21T09:44:49.296429Z","iopub.status.idle":"2023-05-21T09:44:49.480698Z","shell.execute_reply":"2023-05-21T09:44:49.479824Z","shell.execute_reply.started":"2023-05-21T09:44:49.296721Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["for x in range(len(valdata)):\n","    temp = 0\n","    for y in valdata.iloc[x]['Hindi']:\n","        temp+=1\n","    val_max_hin_len = max(val_max_hin_len,temp)\n","print(val_max_hin_len)"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fb2fbe89-21a6-4fd8-969d-d40049fc7f93","_uuid":"788fa87d-c342-40cd-888c-a4c35865062c","collapsed":false,"execution":{"iopub.execute_input":"2023-05-21T09:44:49.482331Z","iopub.status.busy":"2023-05-21T09:44:49.481971Z","iopub.status.idle":"2023-05-21T09:44:51.899793Z","shell.execute_reply":"2023-05-21T09:44:51.898844Z","shell.execute_reply.started":"2023-05-21T09:44:49.482300Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["English_vocab = []\n","for x in range(len(traindata)):\n","    temp = 0\n","    for y in traindata.iloc[x]['English']:\n","        temp += 1\n","        if y not in English_vocab:\n","            English_vocab.append(y)\n","    if(temp>max_eng_len):\n","        max_eng_len = max(max_eng_len,temp)\n","print(sorted(English_vocab))\n","print(max_eng_len)"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ec67d56e-6c2c-4f7e-8930-f44ca3e4d76c","_uuid":"5a5618d2-d7f0-42dc-91c3-99cda7b340d8","collapsed":false,"execution":{"iopub.execute_input":"2023-05-21T09:44:51.901677Z","iopub.status.busy":"2023-05-21T09:44:51.901338Z","iopub.status.idle":"2023-05-21T09:44:54.908482Z","shell.execute_reply":"2023-05-21T09:44:54.906884Z","shell.execute_reply.started":"2023-05-21T09:44:51.901646Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["Hindi_vocab = []\n","for x in range(len(traindata)):\n","    temp = 0\n","    for y in traindata.iloc[x]['Hindi']:\n","        temp += 1\n","        if y not in Hindi_vocab:\n","            Hindi_vocab.append(y)\n","    max_hin_len = max(temp,max_hin_len)\n","for x in range(len(testdata)):\n","    for y in testdata.iloc[x]['Hindi']:\n","        if y not in Hindi_vocab:\n","            print(y)\n","            Hindi_vocab.append(y)"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0cc9278b-25e8-41c5-b0f3-5d6961ea1df7","_uuid":"9d7fc4cb-a5e3-4eb8-b6c3-cc07d5b7ab72","collapsed":false,"execution":{"iopub.execute_input":"2023-05-21T09:44:54.911341Z","iopub.status.busy":"2023-05-21T09:44:54.910963Z","iopub.status.idle":"2023-05-21T09:44:54.915403Z","shell.execute_reply":"2023-05-21T09:44:54.914490Z","shell.execute_reply.started":"2023-05-21T09:44:54.911310Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["English_vocab = sorted(English_vocab)\n","Hindi_vocab = sorted(Hindi_vocab)"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a356075f-b424-409c-951f-8cc137bdad24","_uuid":"88d53253-a949-4df8-9a6c-9dd9ec056185","collapsed":false,"execution":{"iopub.execute_input":"2023-05-21T09:44:54.917583Z","iopub.status.busy":"2023-05-21T09:44:54.916908Z","iopub.status.idle":"2023-05-21T09:44:54.927880Z","shell.execute_reply":"2023-05-21T09:44:54.927011Z","shell.execute_reply.started":"2023-05-21T09:44:54.917549Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["Eng_dict = {}\n","reverse_Eng = {}\n","\n","for x in range(len(English_vocab)):\n","    Eng_dict[English_vocab[x]] = x+3\n","    reverse_Eng[x+3] = English_vocab[x]\n","Eng_dict['<sow>'] = 0\n","Eng_dict['<eow>'] = 1\n","Eng_dict['<pad>'] = 2\n","reverse_Eng[0] = '<sow>'\n","reverse_Eng[1] = '<eow>'\n","reverse_Eng[2] = '<pad>'\n","\n","print(Eng_dict)\n","print(reverse_Eng)"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"13b0a0c6-c07e-40e1-83db-ae8b7217acb7","_uuid":"5afccf3f-421f-4923-afec-54eddb6fc0d2","collapsed":false,"execution":{"iopub.execute_input":"2023-05-21T09:44:54.929539Z","iopub.status.busy":"2023-05-21T09:44:54.929213Z","iopub.status.idle":"2023-05-21T09:44:54.940833Z","shell.execute_reply":"2023-05-21T09:44:54.939849Z","shell.execute_reply.started":"2023-05-21T09:44:54.929508Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["Hin_dict = {}\n","reverse_Hin = {}\n","for x in range(len(Hindi_vocab)):\n","    Hin_dict[Hindi_vocab[x]] = x+3\n","    reverse_Hin[x+3] = Hindi_vocab[x]\n","Hin_dict['<sow>'] = 0\n","Hin_dict['<eow>'] = 1\n","Hin_dict['<pad>'] = 2\n","reverse_Hin[0] = '<sow>'\n","reverse_Hin[1] = '<eow>'\n","reverse_Hin[2] = '<pad>'\n","print(Hin_dict)\n","print(reverse_Hin)"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"dc2a483c-d53e-4412-a46c-95ecd0f9914a","_uuid":"8ed9d941-3255-42de-809f-85cba58d3f58","collapsed":false,"execution":{"iopub.execute_input":"2023-05-21T09:44:54.943654Z","iopub.status.busy":"2023-05-21T09:44:54.942809Z","iopub.status.idle":"2023-05-21T09:44:54.954831Z","shell.execute_reply":"2023-05-21T09:44:54.953945Z","shell.execute_reply.started":"2023-05-21T09:44:54.943483Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["def Eng_tokenize(word):\n","    tokens = []\n","    for x in word:\n","        tokens.append(Eng_dict[x])\n","    for x in range(len(tokens),max_eng_len):\n","        tokens.append(Eng_dict['<pad>'])\n","    return tokens"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"336a6a57-d0bb-4b1b-80d2-0d5e6d5a28d0","_uuid":"433c9cc2-c284-4c35-a030-c20013c81221","collapsed":false,"execution":{"iopub.execute_input":"2023-05-21T09:44:54.956694Z","iopub.status.busy":"2023-05-21T09:44:54.956320Z","iopub.status.idle":"2023-05-21T09:44:54.966037Z","shell.execute_reply":"2023-05-21T09:44:54.964964Z","shell.execute_reply.started":"2023-05-21T09:44:54.956663Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["def Hin_tokenize(word):\n","    tokens = []\n","    for x in word:\n","        tokens.append(Hin_dict[x])\n","    tokens.append(Hin_dict['<eow>'])\n","    for x in range(len(tokens),max_hin_len+1):\n","        tokens.append(Hin_dict['<pad>'])\n","    return tokens"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d9b9daee-7748-4351-b564-b4b43bdc476f","_uuid":"62d4cab5-00bd-4fc6-b6b0-5105c702c9a4","collapsed":false,"execution":{"iopub.execute_input":"2023-05-21T09:44:54.967641Z","iopub.status.busy":"2023-05-21T09:44:54.967348Z","iopub.status.idle":"2023-05-21T09:44:59.817115Z","shell.execute_reply":"2023-05-21T09:44:59.816159Z","shell.execute_reply.started":"2023-05-21T09:44:54.967617Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["eng_word = []\n","hin_word = []\n","for x in range(len(traindata)):\n","    eng_word.append(Eng_tokenize(traindata.iloc[x]['English']))\n","    hin_word.append(Hin_tokenize(traindata.iloc[x]['Hindi']))"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"472431b9-19e3-46c2-8ea7-8b885ffcd4e8","_uuid":"8a58c1b5-de22-4ed9-8574-5664b20e0685","collapsed":false,"execution":{"iopub.execute_input":"2023-05-21T09:44:59.820309Z","iopub.status.busy":"2023-05-21T09:44:59.819600Z","iopub.status.idle":"2023-05-21T09:45:00.593333Z","shell.execute_reply":"2023-05-21T09:45:00.592346Z","shell.execute_reply.started":"2023-05-21T09:44:59.820277Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["eng_word = torch.tensor(eng_word)\n","hin_word = torch.tensor(hin_word)"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"31fe53b1-3b47-4cb1-8c9e-91bd37b99b1c","_uuid":"b7d941e1-a08b-49ee-9fa5-76921fbf4f3b","collapsed":false,"execution":{"iopub.execute_input":"2023-05-21T09:45:00.599393Z","iopub.status.busy":"2023-05-21T09:45:00.598821Z","iopub.status.idle":"2023-05-21T09:45:00.605610Z","shell.execute_reply":"2023-05-21T09:45:00.604683Z","shell.execute_reply.started":"2023-05-21T09:45:00.599365Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["max_hin_len += 1\n","test_max_hin_len += 1\n","val_max_hin_len += 1"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3c6f3b7d-aa12-4877-a13f-cba962fe9378","_uuid":"142d890a-2eeb-41ae-bf60-fec99ac2fc6c","collapsed":false,"execution":{"iopub.execute_input":"2023-05-21T09:45:00.607360Z","iopub.status.busy":"2023-05-21T09:45:00.606836Z","iopub.status.idle":"2023-05-21T09:45:01.563726Z","shell.execute_reply":"2023-05-21T09:45:01.562789Z","shell.execute_reply.started":"2023-05-21T09:45:00.607328Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["def test_Eng_tokenize(word):\n","    tokens = []\n","    for x in word:\n","        tokens.append(Eng_dict[x])\n","    for x in range(len(tokens),test_max_eng_len):\n","        tokens.append(Eng_dict['<pad>'])\n","    return tokens\n","def test_Hin_tokenize(word):\n","    tokens = []\n","    for x in word:\n","        tokens.append(Hin_dict[x])\n","    tokens.append(Hin_dict['<eow>'])\n","    for x in range(len(tokens),test_max_hin_len):\n","        tokens.append(Hin_dict['<pad>'])\n","    return tokens\n","def val_Eng_tokenize(word):\n","    tokens = []\n","    for x in word:\n","        tokens.append(Eng_dict[x])\n","    for x in range(len(tokens),val_max_eng_len):\n","        tokens.append(Eng_dict['<pad>'])\n","    return tokens\n","def val_Hin_tokenize(word):\n","    tokens = []\n","    for x in word:\n","        tokens.append(Hin_dict[x])\n","    tokens.append(Hin_dict['<eow>'])\n","    for x in range(len(tokens),val_max_hin_len):\n","        tokens.append(Hin_dict['<pad>'])\n","    return tokens\n","val_eng_word = []\n","val_hin_word = []\n","for x in range(len(valdata)):\n","    val_eng_word.append(val_Eng_tokenize(valdata.iloc[x]['English']))\n","    val_hin_word.append(val_Hin_tokenize(valdata.iloc[x]['Hindi']))\n","val_eng_word = torch.tensor(val_eng_word)\n","val_hin_word = torch.tensor(val_hin_word)\n","test_eng_word = []\n","test_hin_word = []\n","for x in range(len(testdata)):\n","    test_eng_word.append(test_Eng_tokenize(testdata.iloc[x]['English']))\n","    test_hin_word.append(test_Hin_tokenize(testdata.iloc[x]['Hindi']))\n","test_eng_word = torch.tensor(test_eng_word)\n","test_hin_word = torch.tensor(test_hin_word)"]},{"attachments":{},"cell_type":"markdown","metadata":{"_cell_guid":"1329c375-8eae-484f-9663-4bc5cb229e8c","_uuid":"35d219f5-1265-44af-a552-874a5bc070ac","trusted":true},"source":["### Encoder and Attention Decoder"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a23368c5-348d-42fb-81d7-4c4f822a6cb3","_uuid":"faf8fc04-c1eb-4a28-bd08-5c118cdc3021","collapsed":false,"execution":{"iopub.execute_input":"2023-05-21T09:45:01.565433Z","iopub.status.busy":"2023-05-21T09:45:01.565098Z","iopub.status.idle":"2023-05-21T09:45:01.575309Z","shell.execute_reply":"2023-05-21T09:45:01.574278Z","shell.execute_reply.started":"2023-05-21T09:45:01.565400Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["class Encoder(nn.Module):\n","    def __init__(self,char_embed_size,hidden_size,no_of_layers,dropout,rnn):\n","        super(Encoder,self).__init__()\n","        self.layer = no_of_layers\n","        self.rnn = rnn\n","        self.embedding = nn.Embedding(len(Eng_dict),char_embed_size).to(device)\n","        self.embedding.weight.requires_grad = True\n","        self.drop = nn.Dropout(dropout)\n","        self.LSTM = nn.LSTM(char_embed_size,hidden_size,self.layer,batch_first = True,bidirectional = True).to(device)\n","        self.RNN = nn.RNN(char_embed_size,hidden_size,self.layer,batch_first = True,bidirectional = True).to(device)\n","        self.GRU = nn.GRU(char_embed_size,hidden_size,self.layer,batch_first = True,bidirectional = True).to(device)\n","    def forward(self,input,hidden,cell):\n","        embedded = self.embedding(input)\n","        embedded1 = self.drop(embedded)\n","        cell1 = cell\n","        if(self.rnn == 'RNN'):\n","            output,hidden1 = self.RNN(embedded1,hidden)\n","        elif(self.rnn == 'LSTM'):\n","            output,(hidden1,cell1) = self.LSTM(embedded1,(hidden,cell))\n","        elif(self.rnn == 'GRU'):\n","            output,hidden1 = self.GRU(embedded1,hidden)\n","        return output,(hidden1,cell1)"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"143e2fb7-b9bc-4641-b0bb-0b6ba73b6206","_uuid":"aa9443ed-c25b-4eaf-a0fb-9a6a99665435","collapsed":false,"execution":{"iopub.execute_input":"2023-05-21T09:45:01.577485Z","iopub.status.busy":"2023-05-21T09:45:01.577064Z","iopub.status.idle":"2023-05-21T09:45:01.594588Z","shell.execute_reply":"2023-05-21T09:45:01.593697Z","shell.execute_reply.started":"2023-05-21T09:45:01.577452Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["class Attention(nn.Module):\n","    def __init__(self,char_embed_size,hidden_size,no_of_layers,dropout,batchsize,rnn):\n","        super(Attention,self).__init__()\n","        self.layer = no_of_layers\n","        self.batchsize = batchsize\n","        self.hidden_size = hidden_size\n","        self.rnn = rnn\n","        self.embedding = nn.Embedding(len(Hin_dict),char_embed_size).to(device)\n","        self.drop = nn.Dropout(dropout)\n","        self.embedding.weight.requires_grad = True\n","        self.U = nn.Linear(hidden_size,hidden_size,bias = False).to(device)\n","        self.W = nn.Linear(hidden_size,hidden_size,bias = False).to(device)\n","        self.V = nn.Linear(hidden_size,1,bias = False).to(device)\n","        self.LSTM = nn.LSTM(char_embed_size + hidden_size,hidden_size,self.layer,batch_first = True).to(device)\n","        self.RNN = nn.RNN(char_embed_size + hidden_size,hidden_size,self.layer,batch_first = True).to(device)\n","        self.GRU = nn.GRU(char_embed_size + hidden_size,hidden_size,self.layer,batch_first = True).to(device) \n","        self.linear = nn.Linear(hidden_size,len(Hin_dict),bias=True).to(device)\n","        self.softmax = nn.Softmax(dim = 2).to(device)\n","    def forward(self,input,hidden,cell,encoder_outputs,matrix):\n","        embedded = self.embedding(input)\n","        temp1 = self.U(encoder_outputs)\n","        temp2 = self.W(hidden[-1])\n","        s1 = temp2.size()[0]\n","        s2 = temp2.size()[1]\n","        add = temp1 + temp2.resize(s1,1,s2)\n","        tanh = F.tanh(add)\n","        ejt = self.V(tanh)\n","        ajt = nn.Softmax(dim = 1)(ejt)\n","        ct = torch.zeros(self.batchsize,1,self.hidden_size).to(device)\n","        ct = torch.bmm(ajt.transpose(1,2),encoder_outputs)\n","        final_input = torch.cat((embedded,ct),dim = 2)\n","        final_input = self.drop(final_input)\n","        cell1 = cell\n","        if(self.rnn == 'LSTM'):\n","            output,(hidden1,cell1) = self.LSTM(final_input,(hidden,cell))\n","        elif(self.rnn == 'RNN'):\n","            output,hidden1 = self.RNN(final_input,hidden)\n","        elif(self.rnn == 'GRU'):\n","            output,hidden1 = self.GRU(final_input,hidden)\n","        output1 = self.linear(output)\n","        if(matrix == True):\n","            return ajt,output1,(hidden1,cell1)\n","        return output1,(hidden1,cell1)"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ca7bb393-3846-47a0-977b-548da54e1b9f","_uuid":"bd28e4a9-678a-4ef7-bd72-7fd1551ac6d2","collapsed":false,"execution":{"iopub.execute_input":"2023-05-21T09:45:01.596260Z","iopub.status.busy":"2023-05-21T09:45:01.595789Z","iopub.status.idle":"2023-05-21T09:45:01.610747Z","shell.execute_reply":"2023-05-21T09:45:01.609708Z","shell.execute_reply.started":"2023-05-21T09:45:01.596204Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["def getword(characters):\n","    return \"\".join(characters)"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a485fe44-a05e-49a1-8912-15c726e4bec4","_uuid":"bc2127ac-c255-4a26-8690-ddb12404796b","collapsed":false,"execution":{"iopub.execute_input":"2023-05-21T09:45:01.612445Z","iopub.status.busy":"2023-05-21T09:45:01.611966Z","iopub.status.idle":"2023-05-21T09:45:01.622705Z","shell.execute_reply":"2023-05-21T09:45:01.621765Z","shell.execute_reply.started":"2023-05-21T09:45:01.612413Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["def accuracy(target,predictions,flag):\n","    total = 0\n","    for x in range(len(target)):\n","        if(torch.equal(target[x],predictions[x])):\n","            total += 1\n","    return total"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f2520ea2-b2b8-4e27-9fbb-6ee70d99f964","_uuid":"8c879522-ee0a-490d-937e-abc5ebce5fc0","collapsed":false,"execution":{"iopub.execute_input":"2023-05-21T09:45:01.626207Z","iopub.status.busy":"2023-05-21T09:45:01.625906Z","iopub.status.idle":"2023-05-21T09:45:01.635488Z","shell.execute_reply":"2023-05-21T09:45:01.634424Z","shell.execute_reply.started":"2023-05-21T09:45:01.626184Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["def translate(target,predictions,df):\n","    i = len(df)\n","    for x in range(len(predictions)):\n","        original = []\n","        for y in target[x]:\n","            if(y != 1):\n","                original.append(y)\n","            else:\n","                break\n","        predicted = []\n","        for y in predictions[x]:\n","            if(y != 1):\n","                predicted.append(y)\n","            else:\n","                break\n","        df.loc[i,['Original']] = getword([reverse_Hin[x.item()] for x in original])\n","        df.loc[i,['Predicted']] = getword([reverse_Hin[x.item()] for x in predicted])\n","        i+=1\n","    return df"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"56e8d619-28c3-4503-9b60-8ea586323d6e","_uuid":"39263bc5-594c-489e-9a0e-06722cb5589b","collapsed":false,"execution":{"iopub.execute_input":"2023-05-21T09:45:01.637328Z","iopub.status.busy":"2023-05-21T09:45:01.636934Z","iopub.status.idle":"2023-05-21T09:45:01.654531Z","shell.execute_reply":"2023-05-21T09:45:01.653691Z","shell.execute_reply.started":"2023-05-21T09:45:01.637298Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["def Evaluate(attention,test_eng_word,test_hin_word,encoder,decoder,batchsize,hidden_size,char_embed_size,no_of_layers):\n","    with torch.no_grad():\n","        total_loss = 0\n","        total_acc = 0\n","        df = pd.DataFrame()\n","        en_hidden = torch.zeros(2*no_of_layers,batchsize,hidden_size).to(device)\n","        en_cell = torch.zeros(2*no_of_layers,batchsize,hidden_size).to(device)\n","        for x in range(0,len(testdata),batchsize):\n","            loss = 0\n","            input_tensor = test_eng_word[x:x+batchsize].to(device)\n","            if(input_tensor.size()[0] < batchsize):\n","                break\n","            output,(hidden,cell) = encoder.forward(input_tensor,en_hidden,en_cell)\n","            del(input_tensor)\n","            output = torch.split(output,[hidden_size,hidden_size],dim = 2)\n","            output = torch.add(output[0],output[1])/2\n","            input2 = []\n","            for y in range(batchsize):\n","                input2.append([0])\n","            input2 = torch.tensor(input2).to(device)\n","            hidden = hidden.resize(2,no_of_layers,batchsize,hidden_size)\n","            hidden1 = torch.add(hidden[0],hidden[1])/2\n","            cell = cell.resize(2,no_of_layers,batchsize,hidden_size)\n","            cell1 = torch.add(cell[0],cell[1])/2\n","            OGhidden = hidden1\n","            predicted = []\n","            predictions = []\n","            if(attention == True):\n","                temp = output\n","            else:\n","                temp = OGhidden\n","            for i in range(test_max_hin_len):\n","                output1,(hidden1,cell1) = decoder.forward(input2,hidden1,cell1,temp,False)\n","                predicted.append(output1)\n","                output2 = decoder.softmax(output1)\n","                output3 = torch.argmax(output2,dim = 2)\n","                predictions.append(output3)\n","                input2 = output3\n","            predicted = torch.cat(tuple(x for x in predicted),dim =1).to(device).resize(test_max_hin_len*batchsize,len(Hin_dict))\n","            predictions = torch.cat(tuple(x for x in predictions),dim =1).to(device)\n","            total_acc += accuracy(test_hin_word[x:x+batchsize].to(device),predictions,x)\n","            df = translate(test_hin_word[x:x+batchsize],predictions,df)\n","            loss  = nn.CrossEntropyLoss(reduction = 'sum')(predicted,test_hin_word[x:x+batchsize].reshape(-1).to(device))\n","            with torch.no_grad():\n","                total_loss += loss.item()\n","        test_loss = total_loss/(len(testdata)*test_max_hin_len)\n","        test_accuracy = (total_acc/len(testdata))*100\n","        del(predictions)\n","        del(predicted)\n","        del(input2)\n","        del(output1)\n","        del(output2)\n","        del(output3)\n","        del(hidden1)\n","        del(cell1)\n","        del(OGhidden)\n","        del(output)\n","        del(cell)\n","        return test_loss,test_accuracy,df"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c16f0fa7-9198-43ee-97b1-37cbf5802e8a","_uuid":"e076f517-50d4-4a7c-8255-cfe624cac005","collapsed":false,"execution":{"iopub.execute_input":"2023-05-21T09:45:01.656332Z","iopub.status.busy":"2023-05-21T09:45:01.655959Z","iopub.status.idle":"2023-05-21T09:45:01.674058Z","shell.execute_reply":"2023-05-21T09:45:01.673145Z","shell.execute_reply.started":"2023-05-21T09:45:01.656302Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["def valevaluate(attention,val_eng_word,val_hin_word,encoder,decoder,batchsize,hidden_size,char_embed_size,no_of_layers):\n","    with torch.no_grad():\n","        total_loss = 0\n","        total_acc = 0\n","        for x in range(0,len(valdata),batchsize):\n","            loss = 0\n","            input_tensor = val_eng_word[x:x+batchsize].to(device)\n","#             en_hidden = torch.zeros(2*no_of_layers,batchsize,hidden_size).to(device)\n","            if(input_tensor.size()[0] < batchsize):\n","                break\n","            en_hidden = torch.zeros(2*no_of_layers,batchsize,hidden_size).to(device)\n","            en_cell = torch.zeros(2*no_of_layers,batchsize,hidden_size).to(device)\n","            output,(hidden,cell) = encoder.forward(input_tensor,en_hidden,en_cell)\n","            del(input_tensor)\n","            del(en_hidden)\n","            del(en_cell)\n","            output = torch.split(output,[hidden_size,hidden_size],dim = 2)\n","            output = torch.add(output[0],output[1])/2\n","            input2 = []\n","            for y in range(batchsize):\n","                input2.append([0])\n","            input2 = torch.tensor(input2).to(device)\n","            hidden = hidden.resize(2,no_of_layers,batchsize,hidden_size)\n","            hidden1 = torch.add(hidden[0],hidden[1])/2\n","#             hidden1 = hidden[0]\n","            cell = cell.resize(2,no_of_layers,batchsize,hidden_size)\n","            cell1 = torch.add(cell[0],cell[1])/2\n","#             cell1 = cell[0]\n","            OGhidden = hidden1\n","            predicted = []\n","            predictions = []\n","            if(attention == True):\n","                temp = output\n","            else:\n","                temp = OGhidden\n","            for i in range(val_max_hin_len):\n","                output1,(hidden1,cell1) = decoder.forward(input2,hidden1,cell1,temp,False)\n","                predicted.append(output1)\n","                output2 = decoder.softmax(output1)\n","                output3 = torch.argmax(output2,dim = 2)\n","                predictions.append(output3)\n","                input2 = output3\n","            predicted = torch.cat(tuple(x for x in predicted),dim =1).to(device).resize(val_max_hin_len*batchsize,len(Hin_dict))\n","            predictions = torch.cat(tuple(x for x in predictions),dim =1).to(device)\n","            total_acc += accuracy(val_hin_word[x:x+batchsize].to(device),predictions,x)\n","            loss  = nn.CrossEntropyLoss(reduction = 'sum')(predicted,val_hin_word[x:x+batchsize].reshape(-1).to(device))\n","            with torch.no_grad():\n","                total_loss += loss.item()\n","#             print(loss.item())\n","        validation_loss = total_loss/(len(valdata)*val_max_hin_len)\n","        validation_accuracy = (total_acc/len(valdata))*100\n","        del(predictions)\n","        del(predicted)\n","        del(input2)\n","        del(output1)\n","        del(output2)\n","        del(output3)\n","        del(hidden1)\n","        del(cell1)\n","        del(OGhidden)\n","        del(output)\n","        del(cell)\n","        return validation_loss,validation_accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"726731e3-4ee6-4f0d-b67c-f5a75016e2da","_uuid":"32999b46-7b31-486c-b668-85525434a8e6","collapsed":false,"execution":{"iopub.execute_input":"2023-05-21T09:45:01.675772Z","iopub.status.busy":"2023-05-21T09:45:01.675423Z","iopub.status.idle":"2023-05-21T09:45:01.697969Z","shell.execute_reply":"2023-05-21T09:45:01.697055Z","shell.execute_reply.started":"2023-05-21T09:45:01.675742Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["def attentiontrain(batchsize,hidden_size,char_embed_size,no_of_layers,dropout,epochs,rnn):\n","    gc.collect()\n","    torch.autograd.set_detect_anomaly(True)\n","    encoder = Encoder(char_embed_size,hidden_size,no_of_layers,dropout,rnn).to(device)\n","    decoder = Attention(char_embed_size,hidden_size,no_of_layers,dropout,batchsize,rnn).to(device)\n","    print(encoder.parameters)\n","    print(decoder.parameters)\n","    opt_encoder = optim.Adam(encoder.parameters(),lr = 0.001)\n","    opt_decoder  = optim.Adam(decoder.parameters(),lr = 0.001)\n","    teacher_ratio = 0.5\n","    for _ in range(epochs):\n","        torch.cuda.empty_cache()\n","        print(_)\n","        total_loss = 0\n","        total_acc = 0\n","        for x in range(0,len(traindata),batchsize):\n","            loss = 0\n","            opt_encoder.zero_grad()\n","            opt_decoder.zero_grad()\n","            input_tensor = eng_word[x:x+batchsize].to(device)\n","            en_hidden = torch.zeros(2*no_of_layers,batchsize,hidden_size).to(device)\n","            en_cell = torch.zeros(2*no_of_layers,batchsize,hidden_size).to(device)\n","            if(input_tensor.size()[0] < batchsize):\n","                break\n","            output,(hidden,cell) = encoder.forward(input_tensor,en_hidden,en_cell)\n","            output = torch.split(output,[hidden_size,hidden_size],dim = 2)\n","            output = torch.add(output[0],output[1])/2\n","            input2 = []\n","            for y in range(batchsize):\n","                input2.append([0])\n","            input2 = torch.tensor(input2).to(device)\n","            hidden = hidden.resize(2,no_of_layers,batchsize,hidden_size)\n","            hidden1 = torch.add(hidden[0],hidden[1])/2\n","            cell = cell.resize(2,no_of_layers,batchsize,hidden_size)\n","            cell1 = torch.add(cell[0],cell[1])/2\n","            predicted = []\n","            predictions = []\n","#             use_teacher_forcing = True if random.random() < teacher_ratio else False\n","            for i in range(max_hin_len):\n","                use_teacher_forcing = True if random.random() < teacher_ratio else False\n","                output1,(hidden1,cell1) = decoder.forward(input2,hidden1,cell1,output,False)\n","                predicted.append(output1)\n","                output2 = decoder.softmax(output1)\n","                output3 = torch.argmax(output2,dim = 2)\n","                predictions.append(output3)\n","                if(use_teacher_forcing):\n","                    input2 = hin_word[x:x+batchsize,i].to(device).resize(batchsize,1)\n","                else:\n","                    input2 = hin_word[x:x+batchsize,i].to(device).resize(batchsize,1)\n","            \n","            predicted = torch.cat(tuple(x for x in predicted),dim =1).to(device).resize(max_hin_len*batchsize,len(Hin_dict))\n","            predictions = torch.cat(tuple(x for x in predictions),dim =1).to(device)\n","            total_acc += accuracy(hin_word[x:x+batchsize].to(device),predictions,x)\n","            loss  = nn.CrossEntropyLoss(reduction = 'sum')(predicted,hin_word[x:x+batchsize].reshape(-1).to(device))\n","            with torch.no_grad():\n","                total_loss += loss.item()\n","            loss.backward(retain_graph = True)\n","            torch.nn.utils.clip_grad_norm_(encoder.parameters(),max_norm = 1)\n","            torch.nn.utils.clip_grad_norm_(decoder.parameters(),max_norm = 1)\n","            opt_encoder.step()\n","            opt_decoder.step()\n","        del(input_tensor)\n","        del(en_hidden)\n","        del(en_cell)\n","        del(predictions)\n","        del(predicted)\n","        del(input2)\n","        del(output1)\n","        del(output2)\n","        del(output3)\n","        del(hidden)\n","        del(hidden1)\n","        del(cell1)\n","        del(output)\n","        del(cell)\n","        training_loss = total_loss/(51200*max_hin_len)\n","        training_accuracy = total_acc/512\n","        validation_loss,validation_accuracy = valevaluate(True,val_eng_word,val_hin_word,encoder,decoder,batchsize,hidden_size,char_embed_size,no_of_layers)\n","#         wandb.log({'training_accuracy' : training_accuracy, 'validation_accuracy' : validation_accuracy,'training_loss' : training_loss, 'validation_loss' : validation_loss,'epoch':_+1})\n","#         if(_ >= epochs/2):\n","#             teacher_ratio = 0\n","#         teacher_ratio /= 2\n","    return encoder,decoder"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2a7512f5-dc05-4caf-a546-22509ed8673f","_uuid":"01cfa08f-5840-4e89-bc70-30476380601c","collapsed":false,"execution":{"iopub.execute_input":"2023-05-21T09:45:01.701306Z","iopub.status.busy":"2023-05-21T09:45:01.701027Z","iopub.status.idle":"2023-05-21T09:45:01.722292Z","shell.execute_reply":"2023-05-21T09:45:01.721304Z","shell.execute_reply.started":"2023-05-21T09:45:01.701284Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["def attentionmatrix(attention,test_eng_word,test_hin_word,encoder,decoder,batchsize,hidden_size,char_embed_size,no_of_layers,matrix):\n","    with torch.no_grad():\n","        total_loss = 0\n","        total_acc = 0\n","        en_hidden = torch.zeros(2*no_of_layers,batchsize,hidden_size).to(device)\n","        en_cell = torch.zeros(2*no_of_layers,batchsize,hidden_size).to(device)\n","        plot = []\n","        fig, axes = plt.subplots(3, 3, figsize=(12, 12))\n","        axes = axes.ravel()\n","        for x in range(0,9,1):\n","            attmatrix = []\n","            loss = 0\n","            input_tensor = test_eng_word[x:x+batchsize].to(device)\n","#             en_hidden = torch.zeros(2*no_of_layers,batchsize,hidden_size).to(device)\n","            if(input_tensor.size()[0] < batchsize):\n","                break\n","            output,(hidden,cell) = encoder.forward(input_tensor,en_hidden,en_cell)\n","            del(input_tensor)\n","            output = torch.split(output,[hidden_size,hidden_size],dim = 2)\n","            output = torch.add(output[0],output[1])/2\n","            input2 = []\n","            for y in range(batchsize):\n","                input2.append([0])\n","            input2 = torch.tensor(input2).to(device)\n","            hidden = hidden.resize(2,no_of_layers,batchsize,hidden_size)\n","            hidden1 = torch.add(hidden[0],hidden[1])/2\n","#             hidden1 = hidden[0]\n","            cell = cell.resize(2,no_of_layers,batchsize,hidden_size)\n","            cell1 = torch.add(cell[0],cell[1])/2\n","#             cell1 = cell[0]\n","            OGhidden = hidden1\n","            predicted = []\n","            predictions = []\n","            if(attention == True):\n","                temp = output\n","            else:\n","                temp = OGhidden\n","            for i in range(test_max_hin_len):\n","                if(matrix == True):\n","                    ajt,output1,(hidden1,cell1) = decoder.forward(input2,hidden1,cell1,temp,matrix)\n","                    attmatrix.append(ajt)\n","                else:\n","                    output1,(hidden1,cell1) = decoder.forward(input2,hidden1,cell1,temp,matrix)\n","                predicted.append(output1)\n","                output2 = decoder.softmax(output1)\n","                output3 = torch.argmax(output2,dim = 2)\n","                predictions.append(output3)\n","                input2 = output3\n","            attmatrix = torch.cat(tuple(x for x in attmatrix),dim = 2).to(device)\n","            englen = len(testdata.iloc[x:x+batchsize]['English'][x]) + 1\n","            hinlen = len(testdata.iloc[x:x+batchsize]['Hindi'][x]) + 1\n","            data = attmatrix[0].resize(26,21).cpu().numpy()\n","            y_label_list = [x for x in testdata.iloc[x:x+batchsize]['English'][x]]\n","            y_label_list.append('<EOS>')\n","            x_label_list = [x for x in testdata.iloc[x:x+batchsize]['Hindi'][x]]\n","            x_label_list.append('<EOS>')\n","            sns.heatmap(data[0:englen,0:hinlen],cmap='viridis',ax = axes[x],cbar = True,cbar_kws = {'label':'Value'})\n","            hindi_font = FontProperties(fname=\"/kaggle/input/hello/nirmala.ttf\")\n","            rows,cols = data[0:englen,0:hinlen].shape\n","            axes[x].set_yticks(np.arange(rows) + 0.5)\n","            axes[x].set_yticklabels(y_label_list,rotation = 90)\n","            axes[x].set_xticks(np.arange(cols) +0.5)\n","            axes[x].set_xticklabels(x_label_list,fontproperties = hindi_font)\n","            cbar = axes[x].collections[0].colorbar\n","            cbar.set_label('Value')\n","        fig.savefig(\"ex.png\")\n","        temp = plt.imread(\"ex.png\")\n","        plot.append(temp)\n","        plt.show()\n","        image = wandb.Image(plot[0])\n","        wandb.log({\"attention heatmaps\": image})"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4db5b15b-4413-4b21-bae0-9f9b35c50189","_uuid":"f98b535d-220d-4683-8422-71392e33f12b","collapsed":false,"execution":{"iopub.execute_input":"2023-05-21T09:45:01.725603Z","iopub.status.busy":"2023-05-21T09:45:01.725351Z","iopub.status.idle":"2023-05-21T09:45:08.722913Z","shell.execute_reply":"2023-05-21T09:45:08.721941Z","shell.execute_reply.started":"2023-05-21T09:45:01.725581Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["import wandb\n","wandb.login()"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d7d155dd-dbb5-451a-9ec4-9d6701af18c7","_uuid":"af1fd91a-86d5-4a90-9b7f-1dc728e0e034","collapsed":false,"execution":{"iopub.execute_input":"2023-05-21T09:45:08.724866Z","iopub.status.busy":"2023-05-21T09:45:08.724288Z","iopub.status.idle":"2023-05-21T09:45:24.018383Z","shell.execute_reply":"2023-05-21T09:45:24.017272Z","shell.execute_reply.started":"2023-05-21T09:45:08.724833Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["!pip install GPUtil\n","\n","import torch\n","from GPUtil import showUtilization as gpu_usage\n","from numba import cuda\n","\n","def free_gpu_cache():\n","    print(\"Initial GPU Usage\")\n","    gpu_usage()                             \n","\n","    torch.cuda.empty_cache()\n","\n","    cuda.select_device(0)\n","    cuda.close()\n","    cuda.select_device(0)\n","\n","    print(\"GPU Usage after emptying the cache\")\n","    gpu_usage()"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"bf0de2e5-f214-41c4-87a5-0e786436fd60","_uuid":"420fa388-7934-4986-881d-288ed48f5f36","collapsed":false,"execution":{"iopub.execute_input":"2023-05-21T09:45:24.020680Z","iopub.status.busy":"2023-05-21T09:45:24.020306Z","iopub.status.idle":"2023-05-21T09:45:24.027523Z","shell.execute_reply":"2023-05-21T09:45:24.026547Z","shell.execute_reply.started":"2023-05-21T09:45:24.020631Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["def main():\n","    wandb.init(project='CS6910_DLAssignment3')\n","    config = wandb.config\n","    wandb.run.name = \"_attention_cell_type_{}_bidirec_{}_layers_{}_batchsize_{}_hidden_{}\".format(config.cell_type,config.bidirectional,config.no_of_layers,config.batchsize,config.hidden_size)\n","    hidden_size = config.hidden_size\n","    char_embed_size = config.input_embedding_size\n","    no_of_layers = config.no_of_layers\n","    epochs = config.epochs\n","    batchsize = config.batchsize\n","    dropout = config.dropout\n","    rnn = config.cell_type\n","    Encoder1,Decoder1 = attentiontrain(batchsize,hidden_size,char_embed_size,no_of_layers,dropout,epochs,rnn)\n","    attentionmatrix(True,test_eng_word,test_hin_word,Encoder1,Decoder1,1,hidden_size,char_embed_size,no_of_layers,True)\n","    free_gpu_cache()"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0b332afc-e173-43b4-8fc6-6e7fa923a095","_uuid":"daf0c897-970c-451c-9b63-2c693e42cf47","collapsed":false,"execution":{"iopub.execute_input":"2023-05-21T09:45:24.030284Z","iopub.status.busy":"2023-05-21T09:45:24.028931Z","iopub.status.idle":"2023-05-21T10:51:07.965901Z","shell.execute_reply":"2023-05-21T10:51:07.965070Z","shell.execute_reply.started":"2023-05-21T09:45:24.030247Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["sweep_configuration = {\n","    'method' : 'bayes',\n","    'metric' : { 'goal' : 'maximize',\n","    'name' : 'validation_accuracy'},\n","    'parameters':{\n","        'batchsize' : {'values' : [512]},\n","        'input_embedding_size' : {'values' : [1024]},\n","        'no_of_layers' : {'values' : [1]},\n","        'hidden_size' : {'values' : [1024]},\n","        'cell_type' : {'values' : ['LSTM']},\n","        'bidirectional' : {'values' : ['Yes']},\n","        'dropout' : {'values' : [0.3]},\n","        'epochs' : {'values' : [30]}\n","    }\n","}\n","sweep_id = wandb.sweep(sweep = sweep_configuration,project = 'CS6910_DLAssignment3')\n","wandb.agent(sweep_id,function=main,count = 1)"]},{"attachments":{},"cell_type":"markdown","metadata":{"_cell_guid":"24b59536-a546-4a2e-9f2a-4aeadaf907db","_uuid":"fe4fbbe6-d4ce-489e-9dea-fd06a9d5685d","trusted":true},"source":["## Best configuration for Attention"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f956a348-a185-4b83-82f9-be81b6d4de96","_uuid":"6d943f68-7524-470d-b0f4-f3b5ca0f9f5b","collapsed":false,"execution":{"iopub.execute_input":"2023-05-21T10:51:07.967624Z","iopub.status.busy":"2023-05-21T10:51:07.967286Z","iopub.status.idle":"2023-05-21T10:51:07.974210Z","shell.execute_reply":"2023-05-21T10:51:07.973001Z","shell.execute_reply.started":"2023-05-21T10:51:07.967590Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["batchsize = 512\n","hidden_size = 1024\n","char_embed_size = 1024\n","no_of_layers = 1\n","dropout = 0.4\n","epochs = 30\n","rnn = 'LSTM'"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ef9af3b6-61a5-47d1-9e21-d0cafa1ee736","_uuid":"24b260f4-b5ab-4cf3-8217-310af06f1244","collapsed":false,"execution":{"iopub.execute_input":"2023-05-21T09:31:27.587008Z","iopub.status.busy":"2023-05-21T09:31:27.586246Z","iopub.status.idle":"2023-05-21T09:31:28.353350Z","shell.execute_reply":"2023-05-21T09:31:28.352298Z","shell.execute_reply.started":"2023-05-21T09:31:27.586975Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["free_gpu_cache()"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"233c142b-65d4-432b-af3e-34997adeee5a","_uuid":"088fe974-6d33-42ae-bbff-63d50c7eac15","collapsed":false,"execution":{"iopub.execute_input":"2023-05-21T11:59:21.671323Z","iopub.status.busy":"2023-05-21T11:59:21.670246Z","iopub.status.idle":"2023-05-21T13:05:28.220991Z","shell.execute_reply":"2023-05-21T13:05:28.219973Z","shell.execute_reply.started":"2023-05-21T11:59:21.671276Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["Encoder1,Decoder1 = attentiontrain(batchsize,hidden_size,char_embed_size,no_of_layers,dropout,epochs,rnn)"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2b30a863-5778-4ff2-931d-5c1935b268f1","_uuid":"d3ba5bea-cb9d-4222-924b-cde564b074f4","collapsed":false,"execution":{"iopub.execute_input":"2023-05-21T13:05:28.223282Z","iopub.status.busy":"2023-05-21T13:05:28.222908Z","iopub.status.idle":"2023-05-21T13:05:42.048717Z","shell.execute_reply":"2023-05-21T13:05:42.047788Z","shell.execute_reply.started":"2023-05-21T13:05:28.223250Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["test_loss,test_accuracy,predictions = Evaluate(True,test_eng_word,test_hin_word,Encoder1,Decoder1,batchsize,hidden_size,char_embed_size,no_of_layers)"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b9ffe07c-3e66-4d8c-9520-6930327584c5","_uuid":"ed844902-ae5c-4a23-9861-122678a373dd","collapsed":false,"execution":{"iopub.execute_input":"2023-05-21T13:05:42.050525Z","iopub.status.busy":"2023-05-21T13:05:42.050188Z","iopub.status.idle":"2023-05-21T13:05:42.054848Z","shell.execute_reply":"2023-05-21T13:05:42.053884Z","shell.execute_reply.started":"2023-05-21T13:05:42.050492Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["#combine predictions and english column of testdata and show just head(10)"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"78ba4d8f-e15d-4cc5-b70d-b7e96c1cc0c4","_uuid":"f3adf222-ebd6-49d0-9508-3d4967f5b813","collapsed":false,"execution":{"iopub.execute_input":"2023-05-21T13:05:43.025073Z","iopub.status.busy":"2023-05-21T13:05:43.024060Z","iopub.status.idle":"2023-05-21T13:05:43.030151Z","shell.execute_reply":"2023-05-21T13:05:43.029131Z","shell.execute_reply.started":"2023-05-21T13:05:43.025016Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["print(test_accuracy)"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a58ec625-3f02-491f-b0af-33adab7e51df","_uuid":"5417d3ae-1741-46c4-8492-6bbecfb528af","collapsed":false,"execution":{"iopub.execute_input":"2023-05-21T13:05:42.057825Z","iopub.status.busy":"2023-05-21T13:05:42.057215Z","iopub.status.idle":"2023-05-21T13:05:43.021393Z","shell.execute_reply":"2023-05-21T13:05:43.020393Z","shell.execute_reply.started":"2023-05-21T13:05:42.057791Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["predictions.to_excel(\"output.xlsx\")"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2c9c718d-ba85-4f95-980b-e91a5f8397e4","_uuid":"ca9c18db-537d-4e8d-8bec-9b1bd94e1d6e","collapsed":false,"execution":{"iopub.execute_input":"2023-05-21T13:07:32.197708Z","iopub.status.busy":"2023-05-21T13:07:32.197273Z","iopub.status.idle":"2023-05-21T13:07:32.207391Z","shell.execute_reply":"2023-05-21T13:07:32.206341Z","shell.execute_reply.started":"2023-05-21T13:07:32.197660Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["df = testdata.iloc[0:25]['English']"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"710cae62-cb9c-4071-aaa8-7e8df3364259","_uuid":"e29be8ab-eac0-43f1-86c0-fff387185631","collapsed":false,"execution":{"iopub.execute_input":"2023-05-21T13:07:57.439493Z","iopub.status.busy":"2023-05-21T13:07:57.439135Z","iopub.status.idle":"2023-05-21T13:07:57.449086Z","shell.execute_reply":"2023-05-21T13:07:57.448151Z","shell.execute_reply.started":"2023-05-21T13:07:57.439467Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["l = []\n","for x in df:\n","    l.append(x)\n","print(l)"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"662e5da5-21bd-4bf8-afea-48bfffadb36c","_uuid":"f7cbd611-d640-4bdd-8d8f-3a79fa2dd229","collapsed":false,"execution":{"iopub.execute_input":"2023-05-21T13:09:36.123073Z","iopub.status.busy":"2023-05-21T13:09:36.122660Z","iopub.status.idle":"2023-05-21T13:09:36.129616Z","shell.execute_reply":"2023-05-21T13:09:36.128316Z","shell.execute_reply.started":"2023-05-21T13:09:36.123035Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["for x in l:\n","    print(x)"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cbefd4b6-da0b-4e30-a293-5854a143e939","_uuid":"7dcede7d-cfe4-4130-b9ac-2b42f7e33467","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
