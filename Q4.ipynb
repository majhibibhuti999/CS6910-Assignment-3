{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Importing necessary modules","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2023-05-21T17:09:26.024635Z","iopub.execute_input":"2023-05-21T17:09:26.025061Z","iopub.status.idle":"2023-05-21T17:09:26.110879Z","shell.execute_reply.started":"2023-05-21T17:09:26.025029Z","shell.execute_reply":"2023-05-21T17:09:26.109742Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"/kaggle/input/hello/nirmala.ttf\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/brx/brx_test.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/brx/brx_valid.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/brx/brx_train.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/tam/tam_valid.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/tam/tam_train.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/tam/tam_test.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/mni/mni_valid.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/mni/mni_test.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/mni/mni_train.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/urd/urd_train.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/urd/urd_valid.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/urd/urd_test.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/kok/kok_valid.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/kok/kok_train.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/kok/kok_test.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/mai/mai_test.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/mai/mai_train.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/mai/mai_valid.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/guj/guj_test.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/guj/guj_train.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/guj/guj_valid.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/ben/ben_train.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/ben/ben_test.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/ben/ben_valid.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/tel/tel_test.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/tel/tel_valid.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/tel/tel_train.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/kas/kas_valid.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/kas/kas_train.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/kas/kas_test.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/kan/kan_valid.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/kan/kan_train.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/kan/kan_test.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/mal/mal_test.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/mal/mal_train.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/mal/mal_valid.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/pan/pan_valid.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/pan/pan_test.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/pan/pan_train.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/asm/asm_test.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/asm/asm_train.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/asm/asm_valid.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/sid/sid_train.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/sid/sid_test.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/sid/sid_valid.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/mar/mar_train.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/mar/mar_test.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/mar/mar_valid.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/san/san_train.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/san/san_valid.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/san/san_test.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/hin/hin_valid.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/hin/hin_test.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/hin/hin_train.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/ori/ori_test.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/ori/ori_train.csv\n/kaggle/input/aksharantar-sampled/aksharantar_sampled/ori/ori_valid.csv\n/kaggle/input/predictions/wandb_export_2023-05-20T22_42_50.44605_30.csv\n/kaggle/input/attention/output-3.xlsx\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader\nimport matplotlib.pyplot as plt\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch import optim\nimport gc\nimport random\nimport numpy as np \nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2023-05-21T17:07:44.248259Z","iopub.execute_input":"2023-05-21T17:07:44.248852Z","iopub.status.idle":"2023-05-21T17:07:49.731200Z","shell.execute_reply.started":"2023-05-21T17:07:44.248799Z","shell.execute_reply":"2023-05-21T17:07:49.730160Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"if torch.cuda.is_available():\n    # If CUDA is available, use a CUDA device\n    device = torch.device(\"cuda\")\nelse:\n    # If CUDA is not available, use the CPU\n    device = torch.device(\"cpu\")","metadata":{"execution":{"iopub.status.busy":"2023-05-21T17:07:49.733499Z","iopub.execute_input":"2023-05-21T17:07:49.734100Z","iopub.status.idle":"2023-05-21T17:07:49.807316Z","shell.execute_reply.started":"2023-05-21T17:07:49.734062Z","shell.execute_reply":"2023-05-21T17:07:49.806433Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"device","metadata":{"execution":{"iopub.status.busy":"2023-05-21T17:07:49.809084Z","iopub.execute_input":"2023-05-21T17:07:49.809504Z","iopub.status.idle":"2023-05-21T17:07:49.818766Z","shell.execute_reply.started":"2023-05-21T17:07:49.809465Z","shell.execute_reply":"2023-05-21T17:07:49.817783Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"markdown","source":"### Preprocessing","metadata":{}},{"cell_type":"code","source":"traindata = pd.read_csv('/kaggle/input/aksharantar-sampled/aksharantar_sampled/hin/hin_train.csv',names= ['English','Hindi'],header = None)","metadata":{"execution":{"iopub.status.busy":"2023-05-21T17:07:49.821771Z","iopub.execute_input":"2023-05-21T17:07:49.822739Z","iopub.status.idle":"2023-05-21T17:07:49.939136Z","shell.execute_reply.started":"2023-05-21T17:07:49.822710Z","shell.execute_reply":"2023-05-21T17:07:49.938161Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"testdata = pd.read_csv('/kaggle/input/aksharantar-sampled/aksharantar_sampled/hin/hin_test.csv',names = ['English','Hindi'],header = None)","metadata":{"execution":{"iopub.status.busy":"2023-05-21T17:07:49.940498Z","iopub.execute_input":"2023-05-21T17:07:49.940887Z","iopub.status.idle":"2023-05-21T17:07:49.960055Z","shell.execute_reply.started":"2023-05-21T17:07:49.940850Z","shell.execute_reply":"2023-05-21T17:07:49.959143Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"valdata = pd.read_csv('/kaggle/input/aksharantar-sampled/aksharantar_sampled/hin/hin_valid.csv',names = ['English','Hindi'],header = None)","metadata":{"execution":{"iopub.status.busy":"2023-05-21T17:07:49.962871Z","iopub.execute_input":"2023-05-21T17:07:49.963188Z","iopub.status.idle":"2023-05-21T17:07:49.983874Z","shell.execute_reply.started":"2023-05-21T17:07:49.963153Z","shell.execute_reply":"2023-05-21T17:07:49.981757Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"traindata","metadata":{"execution":{"iopub.status.busy":"2023-05-21T17:07:36.401046Z","iopub.status.idle":"2023-05-21T17:07:36.403498Z","shell.execute_reply.started":"2023-05-21T17:07:36.403210Z","shell.execute_reply":"2023-05-21T17:07:36.403235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def tokenize(word):\n    tokens = []\n    for x in word:\n        tokens.append(x)\n    return tokens","metadata":{"execution":{"iopub.status.busy":"2023-05-21T17:07:36.405389Z","iopub.status.idle":"2023-05-21T17:07:36.409576Z","shell.execute_reply.started":"2023-05-21T17:07:36.409244Z","shell.execute_reply":"2023-05-21T17:07:36.409275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_eng_len = 0\nmax_hin_len = 0\ntest_max_eng_len = 0\ntest_max_hin_len = 0\nval_max_eng_len = 0\nval_max_hin_len = 0","metadata":{"execution":{"iopub.status.busy":"2023-05-21T17:07:36.410962Z","iopub.status.idle":"2023-05-21T17:07:36.411348Z","shell.execute_reply.started":"2023-05-21T17:07:36.411160Z","shell.execute_reply":"2023-05-21T17:07:36.411178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for x in range(len(testdata)):\n    temp = 0\n    for y in testdata.iloc[x]['English']:\n        temp+=1\n    test_max_eng_len = max(test_max_eng_len,temp)\nprint(test_max_eng_len)","metadata":{"execution":{"iopub.status.busy":"2023-05-21T17:07:36.413004Z","iopub.status.idle":"2023-05-21T17:07:36.413495Z","shell.execute_reply.started":"2023-05-21T17:07:36.413244Z","shell.execute_reply":"2023-05-21T17:07:36.413266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for x in range(len(testdata)):\n    temp = 0\n    for y in testdata.iloc[x]['Hindi']:\n        temp +=1\n    test_max_hin_len = max(test_max_hin_len,temp)\nprint(test_max_hin_len)","metadata":{"execution":{"iopub.status.busy":"2023-05-21T17:07:36.415035Z","iopub.status.idle":"2023-05-21T17:07:36.417513Z","shell.execute_reply.started":"2023-05-21T17:07:36.417221Z","shell.execute_reply":"2023-05-21T17:07:36.417248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for x in range(len(valdata)):\n    temp = 0\n    for y in valdata.iloc[x]['English']:\n        temp+=1\n    val_max_eng_len = max(val_max_eng_len,temp)\nprint(val_max_eng_len)","metadata":{"execution":{"iopub.status.busy":"2023-05-21T17:07:36.418507Z","iopub.status.idle":"2023-05-21T17:07:36.419005Z","shell.execute_reply.started":"2023-05-21T17:07:36.418750Z","shell.execute_reply":"2023-05-21T17:07:36.418773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for x in range(len(valdata)):\n    temp = 0\n    for y in valdata.iloc[x]['Hindi']:\n        temp+=1\n    val_max_hin_len = max(val_max_hin_len,temp)\nprint(val_max_hin_len)","metadata":{"execution":{"iopub.status.busy":"2023-05-21T17:07:36.432573Z","iopub.status.idle":"2023-05-21T17:07:36.434138Z","shell.execute_reply.started":"2023-05-21T17:07:36.433467Z","shell.execute_reply":"2023-05-21T17:07:36.433492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"English_vocab = []\nfor x in range(len(traindata)):\n    temp = 0\n    for y in traindata.iloc[x]['English']:\n        temp += 1\n        if y not in English_vocab:\n            English_vocab.append(y)\n    if(temp>max_eng_len):\n        max_eng_len = max(max_eng_len,temp)\nprint(sorted(English_vocab))\nprint(max_eng_len)","metadata":{"execution":{"iopub.status.busy":"2023-05-21T17:07:36.437918Z","iopub.status.idle":"2023-05-21T17:07:36.441372Z","shell.execute_reply.started":"2023-05-21T17:07:36.439163Z","shell.execute_reply":"2023-05-21T17:07:36.439347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Hindi_vocab = []\nfor x in range(len(traindata)):\n    temp = 0\n    for y in traindata.iloc[x]['Hindi']:\n        temp += 1\n        if y not in Hindi_vocab:\n            Hindi_vocab.append(y)\n    max_hin_len = max(temp,max_hin_len)\nfor x in range(len(testdata)):\n    for y in testdata.iloc[x]['Hindi']:\n        if y not in Hindi_vocab:\n            Hindi_vocab.append(y)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-21T17:07:36.444487Z","iopub.status.idle":"2023-05-21T17:07:36.446436Z","shell.execute_reply.started":"2023-05-21T17:07:36.446098Z","shell.execute_reply":"2023-05-21T17:07:36.446147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(Hindi_vocab)","metadata":{"execution":{"iopub.status.busy":"2023-05-21T17:07:36.447926Z","iopub.status.idle":"2023-05-21T17:07:36.450584Z","shell.execute_reply.started":"2023-05-21T17:07:36.450317Z","shell.execute_reply":"2023-05-21T17:07:36.450350Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"English_vocab = sorted(English_vocab)\nHindi_vocab = sorted(Hindi_vocab)","metadata":{"execution":{"iopub.status.busy":"2023-05-21T17:07:36.452722Z","iopub.status.idle":"2023-05-21T17:07:36.454072Z","shell.execute_reply.started":"2023-05-21T17:07:36.453730Z","shell.execute_reply":"2023-05-21T17:07:36.453763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Eng_dict = {}\nreverse_Eng = {}\n\nfor x in range(len(English_vocab)):\n    Eng_dict[English_vocab[x]] = x+3\n    reverse_Eng[x+3] = English_vocab[x]\nEng_dict['<sow>'] = 0\nEng_dict['<eow>'] = 1\nEng_dict['<pad>'] = 2\nreverse_Eng[0] = '<sow>'\nreverse_Eng[1] = '<eow>'\nreverse_Eng[2] = '<pad>'\n\nprint(Eng_dict)\nprint(reverse_Eng)","metadata":{"execution":{"iopub.status.busy":"2023-05-21T17:07:36.457746Z","iopub.status.idle":"2023-05-21T17:07:36.458539Z","shell.execute_reply.started":"2023-05-21T17:07:36.458293Z","shell.execute_reply":"2023-05-21T17:07:36.458316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Hin_dict = {}\nreverse_Hin = {}\nfor x in range(len(Hindi_vocab)):\n    Hin_dict[Hindi_vocab[x]] = x+3\n    reverse_Hin[x+3] = Hindi_vocab[x]\nHin_dict['<sow>'] = 0\nHin_dict['<eow>'] = 1\nHin_dict['<pad>'] = 2\nreverse_Hin[0] = '<sow>'\nreverse_Hin[1] = '<eow>'\nreverse_Hin[2] = '<pad>'\nprint(Hin_dict)\nprint(reverse_Hin)","metadata":{"execution":{"iopub.status.busy":"2023-05-21T17:07:36.460355Z","iopub.status.idle":"2023-05-21T17:07:36.460867Z","shell.execute_reply.started":"2023-05-21T17:07:36.460596Z","shell.execute_reply":"2023-05-21T17:07:36.460621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Eng_tokenize(word):\n    tokens = []\n    for x in word:\n        tokens.append(Eng_dict[x])\n    for x in range(len(tokens),max_eng_len):\n        tokens.append(Eng_dict['<pad>'])\n    return tokens","metadata":{"execution":{"iopub.status.busy":"2023-05-21T17:07:36.463599Z","iopub.status.idle":"2023-05-21T17:07:36.464219Z","shell.execute_reply.started":"2023-05-21T17:07:36.463896Z","shell.execute_reply":"2023-05-21T17:07:36.463921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Hin_tokenize(word):\n    tokens = []\n    for x in word:\n        tokens.append(Hin_dict[x])\n    tokens.append(Hin_dict['<eow>'])\n    for x in range(len(tokens),max_hin_len+1):\n        tokens.append(Hin_dict['<pad>'])\n    return tokens","metadata":{"execution":{"iopub.status.busy":"2023-05-21T17:07:36.466417Z","iopub.status.idle":"2023-05-21T17:07:36.466886Z","shell.execute_reply.started":"2023-05-21T17:07:36.466625Z","shell.execute_reply":"2023-05-21T17:07:36.466648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"eng_word = []\nhin_word = []\nfor x in range(len(traindata)):\n    eng_word.append(Eng_tokenize(traindata.iloc[x]['English']))\n    hin_word.append(Hin_tokenize(traindata.iloc[x]['Hindi']))","metadata":{"execution":{"iopub.status.busy":"2023-05-21T17:07:36.469475Z","iopub.status.idle":"2023-05-21T17:07:36.470071Z","shell.execute_reply.started":"2023-05-21T17:07:36.469759Z","shell.execute_reply":"2023-05-21T17:07:36.469782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"eng_word = torch.tensor(eng_word)\nhin_word = torch.tensor(hin_word)","metadata":{"execution":{"iopub.status.busy":"2023-05-21T17:07:36.471892Z","iopub.status.idle":"2023-05-21T17:07:36.472474Z","shell.execute_reply.started":"2023-05-21T17:07:36.472174Z","shell.execute_reply":"2023-05-21T17:07:36.472202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_hin_len += 1\ntest_max_hin_len += 1\nval_max_hin_len += 1","metadata":{"execution":{"iopub.status.busy":"2023-05-21T17:07:36.473851Z","iopub.status.idle":"2023-05-21T17:07:36.474513Z","shell.execute_reply.started":"2023-05-21T17:07:36.474213Z","shell.execute_reply":"2023-05-21T17:07:36.474241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test_Eng_tokenize(word):\n    tokens = []\n    for x in word:\n        tokens.append(Eng_dict[x])\n    for x in range(len(tokens),test_max_eng_len):\n        tokens.append(Eng_dict['<pad>'])\n    return tokens\ndef test_Hin_tokenize(word):\n    tokens = []\n    for x in word:\n        tokens.append(Hin_dict[x])\n    tokens.append(Hin_dict['<eow>'])\n    for x in range(len(tokens),test_max_hin_len):\n        tokens.append(Hin_dict['<pad>'])\n    return tokens\ndef val_Eng_tokenize(word):\n    tokens = []\n    for x in word:\n        tokens.append(Eng_dict[x])\n    for x in range(len(tokens),val_max_eng_len):\n        tokens.append(Eng_dict['<pad>'])\n    return tokens\ndef val_Hin_tokenize(word):\n    tokens = []\n    for x in word:\n        tokens.append(Hin_dict[x]) \n    tokens.append(Hin_dict['<eow>'])\n    for x in range(len(tokens),val_max_hin_len):\n        tokens.append(Hin_dict['<pad>'])\n    return tokens\nval_eng_word = []\nval_hin_word = []\nfor x in range(len(valdata)):\n    val_eng_word.append(val_Eng_tokenize(valdata.iloc[x]['English']))\n    val_hin_word.append(val_Hin_tokenize(valdata.iloc[x]['Hindi']))\nval_eng_word = torch.tensor(val_eng_word)\nval_hin_word = torch.tensor(val_hin_word)\ntest_eng_word = []\ntest_hin_word = []\nfor x in range(len(testdata)):\n    test_eng_word.append(test_Eng_tokenize(testdata.iloc[x]['English']))\n    test_hin_word.append(test_Hin_tokenize(testdata.iloc[x]['Hindi']))\ntest_eng_word = torch.tensor(test_eng_word)\ntest_hin_word = torch.tensor(test_hin_word)","metadata":{"execution":{"iopub.status.busy":"2023-05-21T17:07:36.476101Z","iopub.status.idle":"2023-05-21T17:07:36.476561Z","shell.execute_reply.started":"2023-05-21T17:07:36.476326Z","shell.execute_reply":"2023-05-21T17:07:36.476347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Encoder and Decoder","metadata":{}},{"cell_type":"code","source":"class Encoder(nn.Module):\n    def __init__(self,char_embed_size,hidden_size,no_of_layers,dropout,rnn):\n        super(Encoder,self).__init__()\n        self.layer = no_of_layers\n        self.rnn = rnn\n        self.embedding = nn.Embedding(len(Eng_dict),char_embed_size).to(device)\n        self.embedding.weight.requires_grad = True\n        self.drop = nn.Dropout(dropout)\n        self.LSTM = nn.LSTM(char_embed_size,hidden_size,self.layer,batch_first = True,bidirectional = True).to(device)\n        self.RNN = nn.RNN(char_embed_size,hidden_size,self.layer,batch_first = True,bidirectional = True).to(device)\n        self.GRU = nn.GRU(char_embed_size,hidden_size,self.layer,batch_first = True,bidirectional = True).to(device)\n    def forward(self,input,hidden,cell):\n        embedded = self.embedding(input)\n        embedded1 = self.drop(embedded)\n        cell1 = cell\n        if(self.rnn == 'RNN'):\n            output,hidden1 = self.RNN(embedded1,hidden)\n        elif(self.rnn == 'LSTM'):\n            output,(hidden1,cell1) = self.LSTM(embedded1,(hidden,cell))\n        elif(self.rnn == 'GRU'):\n            output,hidden1 = self.GRU(embedded1,hidden)\n        return output,(hidden1,cell1)","metadata":{"execution":{"iopub.status.busy":"2023-05-21T17:07:36.480727Z","iopub.status.idle":"2023-05-21T17:07:36.481217Z","shell.execute_reply.started":"2023-05-21T17:07:36.480960Z","shell.execute_reply":"2023-05-21T17:07:36.480981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Decoder(nn.Module):\n    def __init__(self,char_embed_size,hidden_size,no_of_layers,dropout,batchsize,rnn):\n        super(Decoder,self).__init__()\n        self.layer = no_of_layers\n        self.batchsize = batchsize\n        self.hidden_size = hidden_size\n        self.rnn = rnn\n        self.embedding = nn.Embedding(len(Hin_dict),char_embed_size).to(device)\n        self.drop = nn.Dropout(dropout)\n        self.embedding.weight.requires_grad = True\n        self.LSTM = nn.LSTM(char_embed_size + hidden_size*2,hidden_size,self.layer,batch_first = True).to(device)\n        self.RNN = nn.RNN(char_embed_size + hidden_size*2,hidden_size,self.layer,batch_first = True).to(device)\n        self.GRU = nn.GRU(char_embed_size + hidden_size*2,hidden_size,self.layer,batch_first = True).to(device)\n        #2*hidden_size\n        self.linear = nn.Linear(hidden_size,len(Hin_dict),bias=True).to(device)\n        # dim = 2 \n        self.softmax = nn.Softmax(dim = 2).to(device)\n    def forward(self,input,hidden,cell,OGhidden,matrix):\n        embedded = self.embedding(input)\n        s1 = OGhidden.size()[1]\n        s2 = OGhidden.size()[2]\n        embedded1 = torch.cat((embedded,OGhidden[0].resize(s1,1,s2),OGhidden[1].resize(s1,1,s2)),dim = 2)\n        embedded2 = self.drop(embedded1)\n        cell1 = cell\n        if(self.rnn == 'LSTM'):\n            output,(hidden1,cell1) = self.LSTM(embedded2,(hidden,cell))\n        elif(self.rnn == 'RNN'):\n            output,hidden1 = self.RNN(embedded2,hidden)\n        elif(self.rnn == 'GRU'):\n            output,hidden1 = self.GRU(embedded2,hidden)\n        output1 = self.linear(output)\n        return output1,(hidden1,cell1)\n        output2 = self.softmax(output1)\n        return output2,hidden11\n        \n    #changed GRU char_embed_size\n    #changed forward embedded","metadata":{"execution":{"iopub.status.busy":"2023-05-21T17:07:36.487997Z","iopub.status.idle":"2023-05-21T17:07:36.488503Z","shell.execute_reply.started":"2023-05-21T17:07:36.488272Z","shell.execute_reply":"2023-05-21T17:07:36.488293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def getword(characters):\n    return \"\".join(characters)","metadata":{"execution":{"iopub.status.busy":"2023-05-21T17:07:36.490348Z","iopub.status.idle":"2023-05-21T17:07:36.490876Z","shell.execute_reply.started":"2023-05-21T17:07:36.490635Z","shell.execute_reply":"2023-05-21T17:07:36.490657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def accuracy(target,predictions,flag):\n    total = 0\n    for x in range(len(target)):\n        if(torch.equal(target[x],predictions[x])):\n            total += 1\n    return total","metadata":{"execution":{"iopub.status.busy":"2023-05-21T17:07:36.492151Z","iopub.status.idle":"2023-05-21T17:07:36.493879Z","shell.execute_reply.started":"2023-05-21T17:07:36.493585Z","shell.execute_reply":"2023-05-21T17:07:36.493616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def translate(target,predictions,df):\n    i = len(df)\n    for x in range(len(predictions)):\n        original = []\n        for y in target[x]:\n            if(y != 1):\n                original.append(y)\n            else:\n                break\n        predicted = []\n        for y in predictions[x]:\n            if(y != 1):\n                predicted.append(y)\n            else:\n                break\n        df.loc[i,['Original']] = getword([reverse_Hin[x.item()] for x in original])\n        df.loc[i,['Predicted']] = getword([reverse_Hin[x.item()] for x in predicted])\n        i+=1\n    return df\n    ","metadata":{"execution":{"iopub.status.busy":"2023-05-21T17:07:36.495208Z","iopub.status.idle":"2023-05-21T17:07:36.496294Z","shell.execute_reply.started":"2023-05-21T17:07:36.496004Z","shell.execute_reply":"2023-05-21T17:07:36.496026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Evaluate(attention,test_eng_word,test_hin_word,encoder,decoder,batchsize,hidden_size,char_embed_size,no_of_layers):\n    with torch.no_grad():\n        total_loss = 0\n        total_acc = 0\n        df = pd.DataFrame()\n        en_hidden = torch.zeros(2*no_of_layers,batchsize,hidden_size).to(device)\n        en_cell = torch.zeros(2*no_of_layers,batchsize,hidden_size).to(device)\n        for x in range(0,len(testdata),batchsize):\n            loss = 0\n            input_tensor = test_eng_word[x:x+batchsize].to(device)\n            if(input_tensor.size()[0] < batchsize):\n                break\n            output,(hidden,cell) = encoder.forward(input_tensor,en_hidden,en_cell)\n            del(input_tensor)\n            output = torch.split(output,[hidden_size,hidden_size],dim = 2)\n            output = torch.add(output[0],output[1])/2\n            input2 = []\n            for y in range(batchsize):\n                input2.append([0])\n            input2 = torch.tensor(input2).to(device)\n            hidden = hidden.resize(2,no_of_layers,batchsize,hidden_size)\n            hidden1 = torch.add(hidden[0],hidden[1])/2\n            cell = cell.resize(2,no_of_layers,batchsize,hidden_size)\n            cell1 = torch.add(cell[0],cell[1])/2\n            OGhidden = hidden1\n            predicted = []\n            predictions = []\n            if(attention == True):\n                temp = output\n            else:\n                temp = OGhidden\n            for i in range(test_max_hin_len):\n                output1,(hidden1,cell1) = decoder.forward(input2,hidden1,cell1,temp,False)\n                predicted.append(output1)\n                output2 = decoder.softmax(output1)\n                output3 = torch.argmax(output2,dim = 2)\n                predictions.append(output3)\n                input2 = output3\n            predicted = torch.cat(tuple(x for x in predicted),dim =1).to(device).resize(test_max_hin_len*batchsize,len(Hin_dict))\n            predictions = torch.cat(tuple(x for x in predictions),dim =1).to(device)\n            total_acc += accuracy(test_hin_word[x:x+batchsize].to(device),predictions,x)\n            df = translate(test_hin_word[x:x+batchsize],predictions,df)\n            loss  = nn.CrossEntropyLoss(reduction = 'sum')(predicted,test_hin_word[x:x+batchsize].reshape(-1).to(device))\n            with torch.no_grad():\n                total_loss += loss.item()\n        test_loss = total_loss/(len(testdata)*test_max_hin_len)\n        test_accuracy = (total_acc/len(testdata))*100\n        del(predictions)\n        del(predicted)\n        del(input2)\n        del(output1)\n        del(output2)\n        del(output3)\n        del(hidden1)\n        del(cell1)\n        del(OGhidden)\n        del(output)\n        del(cell)\n        return test_loss,test_accuracy,df","metadata":{"execution":{"iopub.status.busy":"2023-05-21T17:07:36.503556Z","iopub.status.idle":"2023-05-21T17:07:36.504399Z","shell.execute_reply.started":"2023-05-21T17:07:36.504101Z","shell.execute_reply":"2023-05-21T17:07:36.504143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def valevaluate(attention,val_eng_word,val_hin_word,encoder,decoder,batchsize,hidden_size,char_embed_size,no_of_layers):\n    with torch.no_grad():\n        total_loss = 0\n        total_acc = 0\n        for x in range(0,len(valdata),batchsize):\n            loss = 0\n            input_tensor = val_eng_word[x:x+batchsize].to(device)\n#             en_hidden = torch.zeros(2*no_of_layers,batchsize,hidden_size).to(device)\n            if(input_tensor.size()[0] < batchsize):\n                break\n            en_hidden = torch.zeros(2*no_of_layers,batchsize,hidden_size).to(device)\n            en_cell = torch.zeros(2*no_of_layers,batchsize,hidden_size).to(device)\n            output,(hidden,cell) = encoder.forward(input_tensor,en_hidden,en_cell)\n            del(input_tensor)\n            del(en_hidden)\n            del(en_cell)\n            output = torch.split(output,[hidden_size,hidden_size],dim = 2)\n            output = torch.add(output[0],output[1])/2\n            input2 = []\n            for y in range(batchsize):\n                input2.append([0])\n            input2 = torch.tensor(input2).to(device)\n            hidden = hidden.resize(2,no_of_layers,batchsize,hidden_size)\n            hidden1 = torch.add(hidden[0],hidden[1])/2\n#             hidden1 = hidden[0]\n            cell = cell.resize(2,no_of_layers,batchsize,hidden_size)\n            cell1 = torch.add(cell[0],cell[1])/2\n#             cell1 = cell[0]\n            OGhidden = hidden1\n            predicted = []\n            predictions = []\n            if(attention == True):\n                temp = output\n            else:\n                temp = OGhidden\n            for i in range(val_max_hin_len):\n                output1,(hidden1,cell1) = decoder.forward(input2,hidden1,cell1,temp,False)\n                predicted.append(output1)\n                output2 = decoder.softmax(output1)\n                output3 = torch.argmax(output2,dim = 2)\n                predictions.append(output3)\n                input2 = output3\n            predicted = torch.cat(tuple(x for x in predicted),dim =1).to(device).resize(val_max_hin_len*batchsize,len(Hin_dict))\n            predictions = torch.cat(tuple(x for x in predictions),dim =1).to(device)\n            total_acc += accuracy(val_hin_word[x:x+batchsize].to(device),predictions,x)\n            loss  = nn.CrossEntropyLoss(reduction = 'sum')(predicted,val_hin_word[x:x+batchsize].reshape(-1).to(device))\n            with torch.no_grad():\n                total_loss += loss.item()\n#             print(loss.item())\n        validation_loss = total_loss/(len(valdata)*val_max_hin_len)\n        validation_accuracy = (total_acc/len(valdata))*100\n        del(predictions)\n        del(predicted)\n        del(input2)\n        del(output1)\n        del(output2)\n        del(output3)\n        del(hidden1)\n        del(cell1)\n        del(OGhidden)\n        del(output)\n        del(cell)\n        return validation_loss,validation_accuracy","metadata":{"execution":{"iopub.status.busy":"2023-05-21T17:07:36.505725Z","iopub.status.idle":"2023-05-21T17:07:36.506296Z","shell.execute_reply.started":"2023-05-21T17:07:36.506040Z","shell.execute_reply":"2023-05-21T17:07:36.506063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(batchsize,hidden_size,char_embed_size,no_of_layers,dropout,epochs,rnn):\n    gc.collect()\n    torch.autograd.set_detect_anomaly(True)\n    encoder = Encoder(char_embed_size,hidden_size,no_of_layers,dropout,rnn).to(device)\n    decoder = Decoder(char_embed_size,hidden_size,no_of_layers,dropout,batchsize,rnn).to(device)\n    print(encoder.parameters)\n    print(decoder.parameters)\n    opt_encoder = optim.Adam(encoder.parameters(),lr = 0.001)\n    opt_decoder  = optim.Adam(decoder.parameters(),lr = 0.001)\n    teacher_ratio = 0.5\n#     en_hidden = torch.randn(2*no_of_layers,batchsize,hidden_size).to(device)\n    for _ in range(epochs):\n        print(_)\n        total_loss = 0\n        total_acc = 0\n        for x in range(0,len(traindata),batchsize):\n            loss = 0\n            opt_encoder.zero_grad()\n            opt_decoder.zero_grad()\n            input_tensor = eng_word[x:x+batchsize].to(device)\n            en_hidden = torch.zeros(2*no_of_layers,batchsize,hidden_size).to(device)\n            en_cell = torch.zeros(2*no_of_layers,batchsize,hidden_size).to(device)\n            if(input_tensor.size()[0] < batchsize):\n                break\n            output,(hidden,cell) = encoder.forward(input_tensor,en_hidden,en_cell)\n            del(en_hidden)\n            del(en_cell)\n            del(input_tensor)\n            input2 = []\n            for y in range(batchsize):\n                input2.append([0])\n            input2 = torch.tensor(input2).to(device)\n            hidden = hidden.resize(2,no_of_layers,batchsize,hidden_size)\n            cell = cell.resize(2,no_of_layers,batchsize,hidden_size)\n            hidden1 = torch.add(hidden[0],hidden[1])/2\n            cell1 = torch.add(cell[0],cell[1])/2\n            OGhidden = hidden1\n            predicted = []\n            predictions = []\n            use_teacher_forcing = True if random.random() < teacher_ratio else False\n            if use_teacher_forcing:\n                for i in range(max_hin_len):\n                    output1,(hidden1,cell1) = decoder.forward(input2,hidden1,cell1,OGhidden,False)\n                    predicted.append(output1)\n                    output2 = decoder.softmax(output1)\n                    output3 = torch.argmax(output2,dim = 2)\n                    predictions.append(output3)\n                    input2 = hin_word[x:x+batchsize,i].to(device).resize(batchsize,1)\n            else:\n                for i in range(max_hin_len):\n                    output1,(hidden1,cell1) = decoder.forward(input2,hidden1,cell1,OGhidden,False)\n                    predicted.append(output1)\n                    output2 = decoder.softmax(output1)\n                    output3 = torch.argmax(output2,dim = 2)\n                    predictions.append(output3)\n                    input2 = output3\n            predicted = torch.cat(tuple(x for x in predicted),dim =1).to(device).resize(max_hin_len*batchsize,len(Hin_dict))\n            predictions = torch.cat(tuple(x for x in predictions),dim =1).to(device)\n            total_acc += accuracy(hin_word[x:x+batchsize].to(device),predictions,x)\n#             print(predicted.shape)\n#             print(hin_word[x:x+batchsize].reshape(-1).shape)\n            loss  = nn.CrossEntropyLoss(reduction = 'sum')(predicted,hin_word[x:x+batchsize].reshape(-1).to(device))\n            with torch.no_grad():\n                total_loss += loss.item()\n            loss.backward(retain_graph = True)\n            torch.nn.utils.clip_grad_norm_(encoder.parameters(),max_norm = 1)\n            torch.nn.utils.clip_grad_norm_(decoder.parameters(),max_norm = 1)\n            opt_encoder.step()\n            opt_decoder.step()\n        del(predictions)\n        del(predicted)\n        del(input2)\n        del(output1)\n        del(output2)\n        del(output3)\n        del(hidden1)\n        del(cell1)\n        del(OGhidden)\n        del(output)\n        del(cell)\n        training_loss = total_loss/(51200*max_hin_len)\n        training_accuracy = total_acc/512\n        validation_loss,validation_accuracy = valevaluate(False,val_eng_word,val_hin_word,encoder,decoder,batchsize,hidden_size,char_embed_size,no_of_layers)\n#         wandb.log({'training_accuracy' : training_accuracy, 'validation_accuracy' : validation_accuracy,'training_loss' : training_loss, 'validation_loss' : validation_loss,'epoch':_+1})\n#         if(_ >= epochs/2):\n#             teacher_ratio = 0\n    return encoder,decoder","metadata":{"execution":{"iopub.status.busy":"2023-05-21T17:07:36.508055Z","iopub.status.idle":"2023-05-21T17:07:36.509187Z","shell.execute_reply.started":"2023-05-21T17:07:36.508902Z","shell.execute_reply":"2023-05-21T17:07:36.508927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import wandb\n# wandb.login()","metadata":{"execution":{"iopub.status.busy":"2023-05-20T14:36:21.459527Z","iopub.execute_input":"2023-05-20T14:36:21.462680Z","iopub.status.idle":"2023-05-20T14:36:21.468784Z","shell.execute_reply.started":"2023-05-20T14:36:21.462639Z","shell.execute_reply":"2023-05-20T14:36:21.467670Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"!pip install GPUtil\n\nimport torch\nfrom GPUtil import showUtilization as gpu_usage\nfrom numba import cuda\n\ndef free_gpu_cache():\n    print(\"Initial GPU Usage\")\n    gpu_usage()                             \n\n    torch.cuda.empty_cache()\n\n    cuda.select_device(0)\n    cuda.close()\n    cuda.select_device(0)\n\n    print(\"GPU Usage after emptying the cache\")\n    gpu_usage()","metadata":{"execution":{"iopub.status.busy":"2023-05-20T14:36:21.474014Z","iopub.execute_input":"2023-05-20T14:36:21.476658Z","iopub.status.idle":"2023-05-20T14:36:39.630476Z","shell.execute_reply.started":"2023-05-20T14:36:21.476619Z","shell.execute_reply":"2023-05-20T14:36:39.629300Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"Collecting GPUtil\n  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hBuilding wheels for collected packages: GPUtil\n  Building wheel for GPUtil (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for GPUtil: filename=GPUtil-1.4.0-py3-none-any.whl size=7409 sha256=be82296761cb21e90ce245472090fa945a6756c6e77e4ed1209ef42713b22e7f\n  Stored in directory: /root/.cache/pip/wheels/a9/8a/bd/81082387151853ab8b6b3ef33426e98f5cbfebc3c397a9d4d0\nSuccessfully built GPUtil\nInstalling collected packages: GPUtil\nSuccessfully installed GPUtil-1.4.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Best configuration\n","metadata":{}},{"cell_type":"code","source":"batchsize = 128\nhidden_size = 1024\nchar_embed_size = 128\nno_of_layers = 2\ndropout = 0.5\nepochs = 20\nrnn = 'LSTM'","metadata":{"execution":{"iopub.status.busy":"2023-05-20T14:36:39.632058Z","iopub.execute_input":"2023-05-20T14:36:39.632768Z","iopub.status.idle":"2023-05-20T14:36:39.639033Z","shell.execute_reply.started":"2023-05-20T14:36:39.632721Z","shell.execute_reply":"2023-05-20T14:36:39.637935Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"Encoder1,Decoder1 = train(batchsize,hidden_size,char_embed_size,no_of_layers,dropout,epochs,rnn)","metadata":{"execution":{"iopub.status.busy":"2023-05-20T14:36:39.640468Z","iopub.execute_input":"2023-05-20T14:36:39.641026Z","iopub.status.idle":"2023-05-20T15:41:29.961201Z","shell.execute_reply.started":"2023-05-20T14:36:39.640988Z","shell.execute_reply":"2023-05-20T15:41:29.960029Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"<bound method Module.parameters of Encoder(\n  (embedding): Embedding(29, 128)\n  (drop): Dropout(p=0.5, inplace=False)\n  (LSTM): LSTM(128, 1024, num_layers=2, batch_first=True, bidirectional=True)\n  (RNN): RNN(128, 1024, num_layers=2, batch_first=True, bidirectional=True)\n  (GRU): GRU(128, 1024, num_layers=2, batch_first=True, bidirectional=True)\n)>\n<bound method Module.parameters of Decoder(\n  (embedding): Embedding(68, 128)\n  (drop): Dropout(p=0.5, inplace=False)\n  (LSTM): LSTM(2176, 1024, num_layers=2, batch_first=True)\n  (RNN): RNN(2176, 1024, num_layers=2, batch_first=True)\n  (GRU): GRU(2176, 1024, num_layers=2, batch_first=True)\n  (linear): Linear(in_features=1024, out_features=68, bias=True)\n  (softmax): Softmax(dim=2)\n)>\n0\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:775: UserWarning: non-inplace resize is deprecated\n  warnings.warn(\"non-inplace resize is deprecated\")\n","output_type":"stream"},{"name":"stdout","text":"1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n","output_type":"stream"}]},{"cell_type":"code","source":"test_loss,test_accuracy,predictions = Evaluate(False,test_eng_word,test_hin_word,Encoder1,Decoder1,batchsize,hidden_size,char_embed_size,no_of_layers)","metadata":{"execution":{"iopub.status.busy":"2023-05-20T15:41:29.963951Z","iopub.execute_input":"2023-05-20T15:41:29.964811Z","iopub.status.idle":"2023-05-20T15:41:44.851622Z","shell.execute_reply.started":"2023-05-20T15:41:29.964763Z","shell.execute_reply":"2023-05-20T15:41:44.850594Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:775: UserWarning: non-inplace resize is deprecated\n  warnings.warn(\"non-inplace resize is deprecated\")\n/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:775: UserWarning: non-inplace resize is deprecated\n  warnings.warn(\"non-inplace resize is deprecated\")\n/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:775: UserWarning: non-inplace resize is deprecated\n  warnings.warn(\"non-inplace resize is deprecated\")\n/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:775: UserWarning: non-inplace resize is deprecated\n  warnings.warn(\"non-inplace resize is deprecated\")\n/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:775: UserWarning: non-inplace resize is deprecated\n  warnings.warn(\"non-inplace resize is deprecated\")\n/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:775: UserWarning: non-inplace resize is deprecated\n  warnings.warn(\"non-inplace resize is deprecated\")\n/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:775: UserWarning: non-inplace resize is deprecated\n  warnings.warn(\"non-inplace resize is deprecated\")\n/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:775: UserWarning: non-inplace resize is deprecated\n  warnings.warn(\"non-inplace resize is deprecated\")\n/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:775: UserWarning: non-inplace resize is deprecated\n  warnings.warn(\"non-inplace resize is deprecated\")\n/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:775: UserWarning: non-inplace resize is deprecated\n  warnings.warn(\"non-inplace resize is deprecated\")\n/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:775: UserWarning: non-inplace resize is deprecated\n  warnings.warn(\"non-inplace resize is deprecated\")\n/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:775: UserWarning: non-inplace resize is deprecated\n  warnings.warn(\"non-inplace resize is deprecated\")\n/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:775: UserWarning: non-inplace resize is deprecated\n  warnings.warn(\"non-inplace resize is deprecated\")\n/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:775: UserWarning: non-inplace resize is deprecated\n  warnings.warn(\"non-inplace resize is deprecated\")\n/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:775: UserWarning: non-inplace resize is deprecated\n  warnings.warn(\"non-inplace resize is deprecated\")\n/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:775: UserWarning: non-inplace resize is deprecated\n  warnings.warn(\"non-inplace resize is deprecated\")\n/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:775: UserWarning: non-inplace resize is deprecated\n  warnings.warn(\"non-inplace resize is deprecated\")\n/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:775: UserWarning: non-inplace resize is deprecated\n  warnings.warn(\"non-inplace resize is deprecated\")\n/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:775: UserWarning: non-inplace resize is deprecated\n  warnings.warn(\"non-inplace resize is deprecated\")\n/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:775: UserWarning: non-inplace resize is deprecated\n  warnings.warn(\"non-inplace resize is deprecated\")\n/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:775: UserWarning: non-inplace resize is deprecated\n  warnings.warn(\"non-inplace resize is deprecated\")\n/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:775: UserWarning: non-inplace resize is deprecated\n  warnings.warn(\"non-inplace resize is deprecated\")\n/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:775: UserWarning: non-inplace resize is deprecated\n  warnings.warn(\"non-inplace resize is deprecated\")\n/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:775: UserWarning: non-inplace resize is deprecated\n  warnings.warn(\"non-inplace resize is deprecated\")\n/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:775: UserWarning: non-inplace resize is deprecated\n  warnings.warn(\"non-inplace resize is deprecated\")\n/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:775: UserWarning: non-inplace resize is deprecated\n  warnings.warn(\"non-inplace resize is deprecated\")\n/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:775: UserWarning: non-inplace resize is deprecated\n  warnings.warn(\"non-inplace resize is deprecated\")\n/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:775: UserWarning: non-inplace resize is deprecated\n  warnings.warn(\"non-inplace resize is deprecated\")\n/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:775: UserWarning: non-inplace resize is deprecated\n  warnings.warn(\"non-inplace resize is deprecated\")\n/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:775: UserWarning: non-inplace resize is deprecated\n  warnings.warn(\"non-inplace resize is deprecated\")\n/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:775: UserWarning: non-inplace resize is deprecated\n  warnings.warn(\"non-inplace resize is deprecated\")\n/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:775: UserWarning: non-inplace resize is deprecated\n  warnings.warn(\"non-inplace resize is deprecated\")\n","output_type":"stream"}]},{"cell_type":"code","source":"test_accuracy","metadata":{"execution":{"iopub.status.busy":"2023-05-20T15:43:21.918781Z","iopub.execute_input":"2023-05-20T15:43:21.919318Z","iopub.status.idle":"2023-05-20T15:43:21.934717Z","shell.execute_reply.started":"2023-05-20T15:43:21.919275Z","shell.execute_reply":"2023-05-20T15:43:21.933714Z"},"trusted":true},"execution_count":41,"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"37.744140625"},"metadata":{}}]},{"cell_type":"code","source":"#combine predictions and english column of testdata and show just head(10)","metadata":{"execution":{"iopub.status.busy":"2023-05-20T15:41:44.853228Z","iopub.execute_input":"2023-05-20T15:41:44.853641Z","iopub.status.idle":"2023-05-20T15:41:44.858913Z","shell.execute_reply.started":"2023-05-20T15:41:44.853604Z","shell.execute_reply":"2023-05-20T15:41:44.857942Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"predictions.to_excel(\"output.xlsx\")","metadata":{"execution":{"iopub.status.busy":"2023-05-20T15:47:42.345326Z","iopub.execute_input":"2023-05-20T15:47:42.346154Z","iopub.status.idle":"2023-05-20T15:47:43.090217Z","shell.execute_reply.started":"2023-05-20T15:47:42.346115Z","shell.execute_reply":"2023-05-20T15:47:43.089161Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"input = pd.DataFrame(testdata.iloc[:]['English'])","metadata":{"execution":{"iopub.status.busy":"2023-05-21T17:11:23.838625Z","iopub.execute_input":"2023-05-21T17:11:23.839002Z","iopub.status.idle":"2023-05-21T17:11:23.848207Z","shell.execute_reply.started":"2023-05-21T17:11:23.838970Z","shell.execute_reply":"2023-05-21T17:11:23.846931Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"input['index'] = input.index","metadata":{"execution":{"iopub.status.busy":"2023-05-21T17:08:10.382536Z","iopub.execute_input":"2023-05-21T17:08:10.383026Z","iopub.status.idle":"2023-05-21T17:08:10.391546Z","shell.execute_reply.started":"2023-05-21T17:08:10.382982Z","shell.execute_reply":"2023-05-21T17:08:10.390556Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"input","metadata":{"execution":{"iopub.status.busy":"2023-05-21T17:08:13.243485Z","iopub.execute_input":"2023-05-21T17:08:13.243928Z","iopub.status.idle":"2023-05-21T17:08:13.264976Z","shell.execute_reply.started":"2023-05-21T17:08:13.243893Z","shell.execute_reply":"2023-05-21T17:08:13.264064Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"           English  index\n0          thermax      0\n1        sikhaaega      1\n2            learn      2\n3         twitters      3\n4      tirunelveli      4\n...            ...    ...\n4091       saflata   4091\n4092        shbana   4092\n4093  khaatootolaa   4093\n4094    shivastava   4094\n4095  preranapuree   4095\n\n[4096 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>English</th>\n      <th>index</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>thermax</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>sikhaaega</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>learn</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>twitters</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>tirunelveli</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4091</th>\n      <td>saflata</td>\n      <td>4091</td>\n    </tr>\n    <tr>\n      <th>4092</th>\n      <td>shbana</td>\n      <td>4092</td>\n    </tr>\n    <tr>\n      <th>4093</th>\n      <td>khaatootolaa</td>\n      <td>4093</td>\n    </tr>\n    <tr>\n      <th>4094</th>\n      <td>shivastava</td>\n      <td>4094</td>\n    </tr>\n    <tr>\n      <th>4095</th>\n      <td>preranapuree</td>\n      <td>4095</td>\n    </tr>\n  </tbody>\n</table>\n<p>4096 rows  2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input = pd.DataFrame(testdata.iloc[:]['English'])\ninput['index'] = input.index\ndf2['index'] = df2.index\nresult = pd.merge(input,df2)","metadata":{"execution":{"iopub.status.busy":"2023-05-21T17:11:36.396186Z","iopub.execute_input":"2023-05-21T17:11:36.397068Z","iopub.status.idle":"2023-05-21T17:11:36.411271Z","shell.execute_reply.started":"2023-05-21T17:11:36.397030Z","shell.execute_reply":"2023-05-21T17:11:36.410274Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"result","metadata":{"execution":{"iopub.status.busy":"2023-05-21T17:11:42.768796Z","iopub.execute_input":"2023-05-21T17:11:42.769221Z","iopub.status.idle":"2023-05-21T17:11:42.788713Z","shell.execute_reply.started":"2023-05-21T17:11:42.769186Z","shell.execute_reply":"2023-05-21T17:11:42.787608Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"           English  index  Unnamed: 0     Original    Predicted\n0          thermax      0           0            \n1        sikhaaega      1           1            \n2            learn      2           2                 \n3         twitters      3           3          \n4      tirunelveli      4           4    \n...            ...    ...         ...          ...          ...\n4091       saflata   4091        4091               \n4092        shbana   4092        4092               \n4093  khaatootolaa   4093        4093          \n4094    shivastava   4094        4094         \n4095  preranapuree   4095        4095    \n\n[4096 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>English</th>\n      <th>index</th>\n      <th>Unnamed: 0</th>\n      <th>Original</th>\n      <th>Predicted</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>thermax</td>\n      <td>0</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>sikhaaega</td>\n      <td>1</td>\n      <td>1</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>learn</td>\n      <td>2</td>\n      <td>2</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>twitters</td>\n      <td>3</td>\n      <td>3</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>tirunelveli</td>\n      <td>4</td>\n      <td>4</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4091</th>\n      <td>saflata</td>\n      <td>4091</td>\n      <td>4091</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>4092</th>\n      <td>shbana</td>\n      <td>4092</td>\n      <td>4092</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>4093</th>\n      <td>khaatootolaa</td>\n      <td>4093</td>\n      <td>4093</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>4094</th>\n      <td>shivastava</td>\n      <td>4094</td>\n      <td>4094</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>4095</th>\n      <td>preranapuree</td>\n      <td>4095</td>\n      <td>4095</td>\n      <td></td>\n      <td></td>\n    </tr>\n  </tbody>\n</table>\n<p>4096 rows  5 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"result.drop()","metadata":{"execution":{"iopub.status.busy":"2023-05-21T17:10:55.725587Z","iopub.execute_input":"2023-05-21T17:10:55.726006Z","iopub.status.idle":"2023-05-21T17:10:55.752206Z","shell.execute_reply.started":"2023-05-21T17:10:55.725973Z","shell.execute_reply":"2023-05-21T17:10:55.751303Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"           English  index  Unnamed: 0     Original    Predicted\n0          thermax      0           0            \n1        sikhaaega      1           1            \n2            learn      2           2                 \n3         twitters      3           3          \n4      tirunelveli      4           4    \n...            ...    ...         ...          ...          ...\n4091       saflata   4091        4091               \n4092        shbana   4092        4092               \n4093  khaatootolaa   4093        4093          \n4094    shivastava   4094        4094         \n4095  preranapuree   4095        4095    \n\n[4096 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>English</th>\n      <th>index</th>\n      <th>Unnamed: 0</th>\n      <th>Original</th>\n      <th>Predicted</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>thermax</td>\n      <td>0</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>sikhaaega</td>\n      <td>1</td>\n      <td>1</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>learn</td>\n      <td>2</td>\n      <td>2</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>twitters</td>\n      <td>3</td>\n      <td>3</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>tirunelveli</td>\n      <td>4</td>\n      <td>4</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4091</th>\n      <td>saflata</td>\n      <td>4091</td>\n      <td>4091</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>4092</th>\n      <td>shbana</td>\n      <td>4092</td>\n      <td>4092</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>4093</th>\n      <td>khaatootolaa</td>\n      <td>4093</td>\n      <td>4093</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>4094</th>\n      <td>shivastava</td>\n      <td>4094</td>\n      <td>4094</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>4095</th>\n      <td>preranapuree</td>\n      <td>4095</td>\n      <td>4095</td>\n      <td></td>\n      <td></td>\n    </tr>\n  </tbody>\n</table>\n<p>4096 rows  5 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"predictions","metadata":{"execution":{"iopub.status.busy":"2023-05-20T16:07:44.906906Z","iopub.execute_input":"2023-05-20T16:07:44.907551Z","iopub.status.idle":"2023-05-20T16:07:44.928576Z","shell.execute_reply.started":"2023-05-20T16:07:44.907484Z","shell.execute_reply":"2023-05-20T16:07:44.927392Z"},"trusted":true},"execution_count":63,"outputs":[{"execution_count":63,"output_type":"execute_result","data":{"text/plain":"         Original    Predicted  index\n0                    0\n1                     1\n2                          2\n3                   3\n4              4\n...           ...          ...    ...\n4091                  4091\n4092                  4092\n4093             4093\n4094            4094\n4095       4095\n\n[4096 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Original</th>\n      <th>Predicted</th>\n      <th>index</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td></td>\n      <td></td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td></td>\n      <td></td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td></td>\n      <td></td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td></td>\n      <td></td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4091</th>\n      <td></td>\n      <td></td>\n      <td>4091</td>\n    </tr>\n    <tr>\n      <th>4092</th>\n      <td></td>\n      <td></td>\n      <td>4092</td>\n    </tr>\n    <tr>\n      <th>4093</th>\n      <td></td>\n      <td></td>\n      <td>4093</td>\n    </tr>\n    <tr>\n      <th>4094</th>\n      <td></td>\n      <td></td>\n      <td>4094</td>\n    </tr>\n    <tr>\n      <th>4095</th>\n      <td></td>\n      <td></td>\n      <td>4095</td>\n    </tr>\n  </tbody>\n</table>\n<p>4096 rows  3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"result = pd.merge(input,predictions)","metadata":{"execution":{"iopub.status.busy":"2023-05-20T16:08:32.717105Z","iopub.execute_input":"2023-05-20T16:08:32.717741Z","iopub.status.idle":"2023-05-20T16:08:32.736017Z","shell.execute_reply.started":"2023-05-20T16:08:32.717697Z","shell.execute_reply":"2023-05-20T16:08:32.734896Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"result = result.drop(['index'],axis = 1)","metadata":{"execution":{"iopub.status.busy":"2023-05-20T16:09:18.118009Z","iopub.execute_input":"2023-05-20T16:09:18.118423Z","iopub.status.idle":"2023-05-20T16:09:18.127895Z","shell.execute_reply.started":"2023-05-20T16:09:18.118371Z","shell.execute_reply":"2023-05-20T16:09:18.126528Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result2 = result.head(20)","metadata":{"execution":{"iopub.status.busy":"2023-05-20T17:07:13.278935Z","iopub.execute_input":"2023-05-20T17:07:13.280108Z","iopub.status.idle":"2023-05-20T17:07:13.305945Z","shell.execute_reply.started":"2023-05-20T17:07:13.280072Z","shell.execute_reply":"2023-05-20T17:07:13.304463Z"},"trusted":true},"execution_count":2,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m result2 \u001b[38;5;241m=\u001b[39m \u001b[43mresult\u001b[49m\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m20\u001b[39m)\n","\u001b[0;31mNameError\u001b[0m: name 'result' is not defined"],"ename":"NameError","evalue":"name 'result' is not defined","output_type":"error"}]},{"cell_type":"code","source":"import wandb\nwandb.login()","metadata":{"execution":{"iopub.status.busy":"2023-05-20T17:20:53.034067Z","iopub.execute_input":"2023-05-20T17:20:53.034650Z","iopub.status.idle":"2023-05-20T17:21:04.930043Z","shell.execute_reply.started":"2023-05-20T17:20:53.034616Z","shell.execute_reply":"2023-05-20T17:21:04.928966Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  \n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"wandb.init(project='CS6910_DLAssignment3')\nwandb.log({'result' : result})","metadata":{"execution":{"iopub.status.busy":"2023-05-20T16:22:57.168524Z","iopub.execute_input":"2023-05-20T16:22:57.168927Z","iopub.status.idle":"2023-05-20T16:23:32.167100Z","shell.execute_reply.started":"2023-05-20T16:22:57.168895Z","shell.execute_reply":"2023-05-20T16:23:32.166079Z"},"trusted":true},"execution_count":73,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Finishing last run (ID:9229gte0) before initializing another..."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">balmy-dragon-1</strong> at: <a href='https://wandb.ai/cs22m031/uncategorized/runs/9229gte0' target=\"_blank\">https://wandb.ai/cs22m031/uncategorized/runs/9229gte0</a><br/>Synced 5 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20230520_161208-9229gte0/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Successfully finished last run (ID:9229gte0). Initializing new run:<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.15.3 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.15.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20230520_162257-0xs7kmf0</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs22m031/CS6910_DLAssignment3/runs/0xs7kmf0' target=\"_blank\">feasible-dawn-80</a></strong> to <a href='https://wandb.ai/cs22m031/CS6910_DLAssignment3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs22m031/CS6910_DLAssignment3' target=\"_blank\">https://wandb.ai/cs22m031/CS6910_DLAssignment3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs22m031/CS6910_DLAssignment3/runs/0xs7kmf0' target=\"_blank\">https://wandb.ai/cs22m031/CS6910_DLAssignment3/runs/0xs7kmf0</a>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Confusion Matrix","metadata":{}},{"cell_type":"code","source":"import pandas as pd","metadata":{"execution":{"iopub.status.busy":"2023-05-20T17:15:46.975695Z","iopub.execute_input":"2023-05-20T17:15:46.976068Z","iopub.status.idle":"2023-05-20T17:15:46.981519Z","shell.execute_reply.started":"2023-05-20T17:15:46.976036Z","shell.execute_reply":"2023-05-20T17:15:46.980560Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/predictions/wandb_export_2023-05-20T22_42_50.44605_30.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-05-20T17:15:48.957753Z","iopub.execute_input":"2023-05-20T17:15:48.958158Z","iopub.status.idle":"2023-05-20T17:15:48.987285Z","shell.execute_reply.started":"2023-05-20T17:15:48.958125Z","shell.execute_reply":"2023-05-20T17:15:48.986328Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2023-05-20T17:15:52.181540Z","iopub.execute_input":"2023-05-20T17:15:52.181889Z","iopub.status.idle":"2023-05-20T17:15:52.202577Z","shell.execute_reply.started":"2023-05-20T17:15:52.181853Z","shell.execute_reply":"2023-05-20T17:15:52.201299Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"           English     Original    Predicted\n0          thermax           \n1        sikhaaega            \n2            learn                 \n3         twitters          \n4      tirunelveli     \n...            ...          ...          ...\n4091       saflata               \n4092        shbana               \n4093  khaatootolaa          \n4094    shivastava         \n4095  preranapuree    \n\n[4096 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>English</th>\n      <th>Original</th>\n      <th>Predicted</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>thermax</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>sikhaaega</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>learn</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>twitters</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>tirunelveli</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4091</th>\n      <td>saflata</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>4092</th>\n      <td>shbana</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>4093</th>\n      <td>khaatootolaa</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>4094</th>\n      <td>shivastava</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>4095</th>\n      <td>preranapuree</td>\n      <td></td>\n      <td></td>\n    </tr>\n  </tbody>\n</table>\n<p>4096 rows  3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"target = []\npredicted  = []\nfor x in range(len(df.iloc[:]['Original'])):\n    if(len(df.iloc[x]['Original']) < len(df.iloc[x]['Predicted'])):\n        for y in range(len(df.iloc[x]['Original'])):\n            target.append(Hin_dict[df.iloc[x]['Original'][y]]-3)\n            predicted.append(Hin_dict[df.iloc[x]['Predicted'][y]]-3)\n    else:\n        for y in range(len(df.iloc[x]['Predicted'])):\n            target.append(Hin_dict[df.iloc[x]['Original'][y]]-3)\n            predicted.append(Hin_dict[df.iloc[x]['Predicted'][y]]-3)\n        \n        ","metadata":{"execution":{"iopub.status.busy":"2023-05-20T17:50:53.825571Z","iopub.execute_input":"2023-05-20T17:50:53.825985Z","iopub.status.idle":"2023-05-20T17:50:56.781423Z","shell.execute_reply.started":"2023-05-20T17:50:53.825951Z","shell.execute_reply":"2023-05-20T17:50:56.780060Z"},"trusted":true},"execution_count":92,"outputs":[]},{"cell_type":"code","source":"max(target)","metadata":{"execution":{"iopub.status.busy":"2023-05-20T17:51:17.097244Z","iopub.execute_input":"2023-05-20T17:51:17.097649Z","iopub.status.idle":"2023-05-20T17:51:17.107054Z","shell.execute_reply.started":"2023-05-20T17:51:17.097617Z","shell.execute_reply":"2023-05-20T17:51:17.106188Z"},"trusted":true},"execution_count":96,"outputs":[{"execution_count":96,"output_type":"execute_result","data":{"text/plain":"64"},"metadata":{}}]},{"cell_type":"code","source":"max(predicted)","metadata":{"execution":{"iopub.status.busy":"2023-05-20T17:51:01.214833Z","iopub.execute_input":"2023-05-20T17:51:01.215773Z","iopub.status.idle":"2023-05-20T17:51:01.228958Z","shell.execute_reply.started":"2023-05-20T17:51:01.215736Z","shell.execute_reply":"2023-05-20T17:51:01.227956Z"},"trusted":true},"execution_count":94,"outputs":[{"execution_count":94,"output_type":"execute_result","data":{"text/plain":"64"},"metadata":{}}]},{"cell_type":"code","source":"len(Hindi_vocab)","metadata":{"execution":{"iopub.status.busy":"2023-05-20T17:46:50.014459Z","iopub.execute_input":"2023-05-20T17:46:50.014807Z","iopub.status.idle":"2023-05-20T17:46:50.026721Z","shell.execute_reply.started":"2023-05-20T17:46:50.014779Z","shell.execute_reply":"2023-05-20T17:46:50.024982Z"},"trusted":true},"execution_count":72,"outputs":[{"execution_count":72,"output_type":"execute_result","data":{"text/plain":"65"},"metadata":{}}]},{"cell_type":"code","source":"wandb.init(project='CS6910_DLAssignment3')\nwandb.log({\"conf_mat\" : wandb.sklearn.plot_confusion_matrix(target,predicted,Hindi_vocab)})","metadata":{"execution":{"iopub.status.busy":"2023-05-20T18:49:38.771463Z","iopub.execute_input":"2023-05-20T18:49:38.771881Z","iopub.status.idle":"2023-05-20T18:50:16.134092Z","shell.execute_reply.started":"2023-05-20T18:49:38.771850Z","shell.execute_reply":"2023-05-20T18:50:16.133108Z"},"trusted":true},"execution_count":102,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Finishing last run (ID:26x3l1y1) before initializing another..."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.050 MB of 0.050 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0868b32202cc448498a4183e38e87417"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">worthy-moon-85</strong> at: <a href='https://wandb.ai/cs22m031/CS6910_DLAssignment3/runs/26x3l1y1' target=\"_blank\">https://wandb.ai/cs22m031/CS6910_DLAssignment3/runs/26x3l1y1</a><br/>Synced 6 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20230520_182719-26x3l1y1/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Successfully finished last run (ID:26x3l1y1). Initializing new run:<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.15.3 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.15.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20230520_184938-qyl5z0k8</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs22m031/CS6910_DLAssignment3/runs/qyl5z0k8' target=\"_blank\">rich-wood-86</a></strong> to <a href='https://wandb.ai/cs22m031/CS6910_DLAssignment3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs22m031/CS6910_DLAssignment3' target=\"_blank\">https://wandb.ai/cs22m031/CS6910_DLAssignment3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs22m031/CS6910_DLAssignment3/runs/qyl5z0k8' target=\"_blank\">https://wandb.ai/cs22m031/CS6910_DLAssignment3/runs/qyl5z0k8</a>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m using only the first 1000 datapoints to create chart confusion_matrix\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}